Article Title,Author,Journal Title,ISSN,ISBN,Publication Date,Volume,Issue,First Page,Page Count,Accession Number,DOI,Publisher,Doctype,Subjects,Keywords,Abstract,PLink
"A computational model for speech disorders using problematic phonemes with ontological reasoning.","Vázquez González, Stephanie; Somodevilla García, María; Pinto, David; Singh, Vivek; Perez, Fernando","Journal of Intelligent & Fuzzy Systems",="10641246",,="2020","39","2","2305","11","145429362","10.3233/JIFS-179892","IOS Press","Article","NATURAL language processing; INFORMATION retrieval; SPEECH disorders; ONTOLOGIES (Information retrieval)","Corpus building; ontology; problematic phonemes; speech disorders","This work presents a method for data gathering to construct a corpus related to speech disorders in children; such corpus will serve as the base to generate some semi-automatic ontologies, in order to become a computational model to support therapists for diagnosis and possible treatment. Speech disorders, phonemes and some additional information are classified using taxonomies obtained from speech disorders specialized literature. Based on the obtained taxonomies, the ontologies, which structure and formalize concepts defined by the main topic authors, are developed. The ontologies are constructed following some parts of classic methodologies and their subsequent validation is made through competency questions. The development of the model is based on Natural Language Processing (NLP) and Information Retrieval (IR) techniques. Integration of the ontologies is made to be able to make a classification based in problematic phonemes; this is suggested as a complement to the diagnostic tool in the model. [ABSTRACT FROM AUTHOR] Copyright of Journal of Intelligent & Fuzzy Systems is the property of IOS Press and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=145429362&site=bsi-live"
"A survey on evaluation of summarization methods.","Ermakova, Liana; Cossu, Jean Valère; Mothe, Josiane","Information Processing & Management",="03064573",,="Sep2019","56","5","1794","21","137094084","10.1016/j.ipm.2019.04.001","Elsevier B.V.","Article","DATA mining; INFORMATION retrieval; Nature Parks and Other Similar Institutions; EVALUATION methodology; NATURE reserves; WIKIPEDIA","Assessment metrics; Automatic summarization; Evaluation campaigns; Extraction; Extractive summarization; ROUGE; Text compression","• Manual assessment is not re-usable. • Re-use of the gold standard by non-participants is often problematic. • Overlap-based metrics are not suitable for full text comparison-based evaluation. • GRAD exceeds word-based metrics to distinguish between generated and human written summaries. • Overlap metrics and GRAD can identify native abstracts among ones from different texts. • Existing metrics, except GEM, have relative values and so are not interpretable. • The majority of the metrics are normalized, but in practice, their values tend to 0. The increasing volume of textual information on any topic requires its compression to allow humans to digest it. This implies detecting the most important information and condensing it. These challenges have led to new developments in the area of Natural Language Processing (NLP) and Information Retrieval (IR) such as narrative summarization and evaluation methodologies for narrative extraction. Despite some progress over recent years with several solutions for information extraction and text summarization, the problems of generating consistent narrative summaries and evaluating them are still unresolved. With regard to evaluation, manual assessment is expensive, subjective and not applicable in real time or to large collections. Moreover, it does not provide re-usable benchmarks. Nevertheless, commonly used metrics for summary evaluation still imply substantial human effort since they require a comparison of candidate summaries with a set of reference summaries. The contributions of this paper are three-fold. First, we provide a comprehensive overview of existing metrics for summary evaluation. We discuss several limitations of existing frameworks for summary evaluation. Second, we introduce an automatic framework for the evaluation of metrics that does not require any human annotation. Finally, we evaluate the existing assessment metrics on a Wikipedia data set and a collection of scientific articles using this framework. Our findings show that the majority of existing metrics based on vocabulary overlap are not suitable for assessment based on comparison with a full text and we discuss this outcome. [ABSTRACT FROM AUTHOR] Copyright of Information Processing & Management is the property of Pergamon Press - An Imprint of Elsevier Science and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=137094084&site=bsi-live"
"A Survey on Event-Based News Narrative Extraction.","NORAMBUENA, BRIAN FELIPE KEITH; MITRA, TANUSHREE; NORTH, CHRIS","ACM Computing Surveys",="03600300",,="2023 Suppl14s","55",,"1","39","169992784","10.1145/3584741","Association for Computing Machinery","Article","ARTIFICIAL intelligence; KNOWLEDGE representation (Information theory)","Computational narratives; narrative analysis; narrative extraction; narrative representation","Narratives are fundamental to our understanding of the world, providing us with a natural structure for knowledge representation over time. Computational narrative extraction is a subfield of artificial intelligence that makes heavy use of information retrieval and natural language processing techniques. Despite the importance of computational narrative extraction, relatively little scholarly work exists on synthesizing previous research and strategizing future research in the area. In particular, this article focuses on extracting news narratives from an event-centric perspective. Extracting narratives from news data has multiple applications in understanding the evolving information landscape. This survey presents an extensive study of research in the area of event-based news narrative extraction. In particular, we screened more than 900 articles, which yielded 54 relevant articles. These articles are synthesized and organized by representation model, extraction criteria, and evaluation approaches. Based on the reviewed studies, we identify recent trends, open challenges, and potential research lines. [ABSTRACT FROM AUTHOR] Copyright of ACM Computing Surveys is the property of Association for Computing Machinery and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=169992784&site=bsi-live"
"A Systematic Review of the Limitations and Associated Opportunities of ChatGPT.","Cong-Lem, Ngo; Soyoof, Ali; Tsering, Diki","International Journal of Human-Computer Interaction",="10447318",,="May2024",,,"1","16","177102411","10.1080/10447318.2024.2344142","Taylor & Francis Ltd","Article",,"ChatGPT; large language model; limitation; opportunity; review","AbstractThis systematic review explores the limitations and opportunities associated with ChatGPT's application across various fields. Following a rigorous screening process of 485 studies identified through searches in Scopus, Web of Science, ERIC, and IEEE Xplore databases, 33 high-quality empirical studies were selected for analysis. The review identifies five key limitations: accuracy and reliability concerns, limitations in critical thinking and problem-solving, multifaceted impacts on learning and development, technical constraints related to input and output, and ethical, legal, and privacy concerns. However, the review also highlights five exciting opportunities: educational support and skill development, workflow enhancement, information retrieval, natural language interaction and assistance, and content creation and ideation. While this review provides valuable insights, it also highlights some gaps. Limited transparency in the studies regarding specific ChatGPT versions used hinders generalizability. Additionally, the extent to which these findings can be transferred to more advanced models like ChatGPT-4 remains unclear. By acknowledging both limitations and opportunities, this review offers a foundation for researchers, developers, and practitioners to consider when exploring the potential and responsible application of ChatGPT and similar evolving AI tools. [ABSTRACT FROM AUTHOR] Copyright of International Journal of Human-Computer Interaction is the property of Taylor & Francis Ltd and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=177102411&site=bsi-live"
"Accelerating range minimum queries with ray tracing cores.","Meneses, Enzo; Navarro, Cristóbal A.; Ferrada, Héctor; Quezada, Felipe A.","Future Generation Computer Systems",="0167739X",,="Aug2024","157",,"98","14","177222150","10.1016/j.future.2024.03.040","Elsevier B.V.","Article","RAY tracing; APPLICATION-specific integrated circuits; GRAPHICS processing units; SOURCE code; CENTRAL processing units","Bounding volume hierarchy; Energy efficiency; GPU computing; Range minimum query; Ray tracing; RT cores","Over the past decade, GPU technology has undergone a notable transformation, evolving from pure general-purpose computation to the integration of application-specific integrated circuits (ASICs), including Tensor Cores and Ray Tracing (RT) cores. While these specialized GPU cores were initially developed to enhance specific domains like AI and real-time rendering, recent research has successfully harnessed their capabilities to expedite other tasks traditionally reliant on conventional GPU computing. One GPU task that is still yet to find its way into RT cores is the processing of range minimum queries (RMQs) in parallel, which is fundamental in fields such as information retrieval or pattern matching, among others. In this context, accelerating RMQs with RT cores would impact many of the applications that heavily rely on this task. In this work we present RTXRMQ, a new approach that can compute RMQs with RT cores. The main contribution is the proposal of a geometric solution for RMQ, where elements become triangles that are placed and shaped according to the element's value and position in the array, respectively, such that the closest hit of a ray launched from a point given by the query parameters corresponds to the result of that query. Experimental results show that RTXRMQ is currently best suited for small query ranges relative to the input size, achieving up to 5 × and 2. 3 × of speedup over parallel state of the art CPU and GPU approaches, respectively. For medium and large query ranges RTXRMQ is still slower than the state of the art GPU approach, but still competitive by being 2. 5 × and 4 × faster than a state of the art CPU method running in parallel as well. Furthermore, performance scaling experiments across the latest RTX GPU architectures show that if the current RT core scaling trend continues, then RTXRMQ's performance would scale at a higher rate than the other compared approaches, making it an attractive tool for future high performance applications that employ many batches of RMQs. • A parallel Range Minimum Query (RMQ) approach that uses GPU Ray Tracing Cores. • Fastest performance of all tested approaches for small RMQ ranges. • Competitive performance for medium and large query ranges. • Favorable performance scaling across GPU architectures. • RTXRMQ source code available for the community. [ABSTRACT FROM AUTHOR] Copyright of Future Generation Computer Systems is the property of Elsevier B.V. and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=177222150&site=bsi-live"
"An artificial intelligence agent technology based web distance education system.","Li, Ruisheng","Journal of Intelligent & Fuzzy Systems",="10641246",,="Sep2020",,,"1","11","147564168","10.3233/jifs-189369","IOS Press","Article",,"agent technology; Artificial intelligence; system design; web distance education","Based on the analysis of the characteristics of artificial intelligence and agent, this paper discusses the feasibility of introducing Web services and intelligent agent technology into online teaching and learning and proposes a modern distance education system model based on artificial intelligence agent technology web. The architecture integrates the advantages of Agent technology and Web services. Starting from improving the shortcomings of the traditional Web-based distance teaching system, it strives to increase learners’ self-directed learning interest, monitor students’ emotions, and exchange knowledge between teaching agents. To realize students’ on-demand learning according to their aptitude, teachers’ teaching ultimately improve the system’s flexibility, personalization, and artificial intelligence. Under the guidance of learning communities and other theories, construct learner model ontology inference rules. Based on the learner’s relationship characteristics, the knowledge domain that the learner is interested in is inferred, thus constructing an intelligent information retrieval system. Knowledge retrieval is realized quickly and accurately, thereby verifying the application of learner relationship characteristics in digital learning. [ABSTRACT FROM AUTHOR] Copyright of Journal of Intelligent & Fuzzy Systems is the property of IOS Press and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=147564168&site=bsi-live"
"An ensemble model for classifying idioms and literal texts using BERT and RoBERTa.","Briskilal, J; Subalalitha, C.N.","Information Processing & Management",="03064573",,="Jan2022","59","1","N.PAG","1","153680172","10.1016/j.ipm.2021.102756","Elsevier B.V.","Article","NATURAL language processing; DEEP learning; IDIOMS; MACHINE translating","BERT; Ensemble model; Idiom; Literal classification; RoBERTa","• Fundamental NLP categorizes text into structured categories. • We propose a predictive ensemble model to classify idioms and literals. • We user BERT and RoBERTa, fine-tuned with the Trofi dataset. • Model is tested with a newly created dataset of idioms and literal expressions, numbering 1470 in all, and annotated by domain experts. An idiom is a common phrase that means something other than its literal meaning. Detecting idioms automatically is a serious challenge in natural language processing (NLP) domain applications like information retrieval (IR), machine translation and chatbot. Automatic detection of Idioms plays an important role in all these applications. A fundamental NLP task is text classification, which categorizes text into structured categories known as text labeling or categorization. This paper deals with idiom identification as a text classification task. Pre-trained deep learning models have been used for several text classification tasks; though models like BERT and RoBERTa have not been exclusively used for idiom and literal classification. We propose a predictive ensemble model to classify idioms and literals using BERT and RoBERTa, fine-tuned with the TroFi dataset. The model is tested with a newly created in house dataset of idioms and literal expressions, numbering 1470 in all, and annotated by domain experts. Our model outperforms the baseline models in terms of the metrics considered, such as F-score and accuracy, with a 2% improvement in accuracy. [ABSTRACT FROM AUTHOR] Copyright of Information Processing & Management is the property of Pergamon Press - An Imprint of Elsevier Science and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=153680172&site=bsi-live"
"An improved Urdu stemming algorithm for text mining based on multi-step hybrid approach.","Jabbar, Abdul; Iqbal, Sajid; Akhunzada, Adnan; Abbas, Qaisar","Journal of Experimental & Theoretical Artificial Intelligence",="0952813X",,="Sep2018","30","5","703","21","132054653","10.1080/0952813X.2018.1467495","Taylor & Francis Ltd","Article","ARTIFICIAL intelligence; ALGORITHMS; DATA mining; ELECTRONIC data processing; Data Processing, Hosting, and Related Services; MACHINE learning","affixes; information retrieval; lemmatization; natural language processing; stemming; text mining; Urdu; Urdu stemmer","Stemming is the basic operation in Natural language processing (NLP) to remove derivational and inflectional affixes without performing a morphological analysis. This practice is essential to extract the root or stem. In NLP domains, the stemmer is used to improve the process of information retrieval (IR), text classifications (TC), text mining (TM) and related applications. In particular, Urdu stemmers utilize only uni-gram words from the input text by ignoring bigrams, trigrams, and n-gram words. To improve the process and efficiency of stemming, bigrams and trigram words must be included. Despite this fact, there are a few developed methods for Urdu stemmers in the past studies. Therefore, in this paper, we proposed an improved Urdu stemmer, using hybrid approach divided into multi-step operation, to deal with unigram, bigram, and trigram features as well. To evaluate the proposed Urdu stemming method, we have used two corpora; word corpus and text corpus. Moreover, two different evaluation metrics have been applied to measure the performance of the proposed algorithm. The proposed algorithm achieved an accuracy of 92.97% and compression rate of 55%. These experimental results indicate that the proposed system can be used to increase the effectiveness and efficiency of the Urdu stemmer for better information retrieval and text mining applications. [ABSTRACT FROM AUTHOR] Copyright of Journal of Experimental & Theoretical Artificial Intelligence is the property of Taylor & Francis Ltd and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=132054653&site=bsi-live"
"Applications of natural language processing in software traceability: A systematic mapping study.","Pauzi, Zaki; Capiluppi, Andrea","Journal of Systems & Software",="01641212",,="Apr2023","198",,"N.PAG","1","161845363","10.1016/j.jss.2023.111616","Elsevier B.V.","Article","NATURAL language processing; COMPUTER software; INFORMATION retrieval; Computer, computer peripheral and pre-packaged software merchant wholesalers; Computer and Computer Peripheral Equipment and Software Merchant Wholesalers; Computer and software stores; Software publishers (except video game publishers); TACIT knowledge; SOFTWARE maintenance; SOURCE code; TREND analysis","Information retrieval; Natural language processing; Software traceability","A key part of software evolution and maintenance is the continuous integration from collaborative efforts, often resulting in complex traceability challenges between software artifacts: features and modules remain scattered in the source code, and traceability links become harder to recover. In this paper, we perform a systematic mapping study dealing with recent research recovering these links through information retrieval, with a particular focus on natural language processing (NLP). Our search strategy gathered a total of 96 papers in focus of our study, covering a period from 2013 to 2021. We conducted trend analysis on NLP techniques and tools involved, and traceability efforts (applying NLP) across the software development life cycle (SDLC). Based on our study, we have identified the following key issues, barriers, and setbacks: syntax convention, configuration, translation, explainability, properties representation, tacit knowledge dependency, scalability, and data availability. Based on these, we consolidated the following open challenges: representation similarity across artifacts, the effectiveness of NLP for traceability, and achieving scalable, adaptive, and explainable models. To address these challenges, we recommend a holistic framework for NLP solutions to achieve effective traceability and efforts in achieving interoperability and explainability in NLP models for traceability. [Display omitted] • Our search strategy across multiple library databases gathered a total of 96 papers. • Trend analysis was conducted throughout the years 2013 to 2021. • Our study highlighted open challenges from key issues, barriers, and setbacks. • We proposed two key recommendations to address these open challenges. [ABSTRACT FROM AUTHOR] Copyright of Journal of Systems & Software is the property of Elsevier B.V. and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=161845363&site=bsi-live"
"Assessment Scale and Behavioral Model Construction for AI Chat Information Retrieval and Processing Service Systems Based on Behavioral Reasoning Theory—Taking ChatGPT-Like Tools as an Example.","Wang, Zheng; Wang, Zhiyuan; Deng, Rong","International Journal of Human-Computer Interaction",="10447318",,="Apr2024",,,"1","22","176427904","10.1080/10447318.2024.2331855","Taylor & Francis Ltd","Article",,"AI chat information retrieval and processing services; behavioral reasoning theory framework; ChatGPT; intention to; linear regression; use","AbstractChatGPT and other AI chat information retrieval and processing service systems can deal with many problems, which are crucial for users, yet current research lacks depth in user experience. And those studies predominantly focus on positive aspects of user intention, which have a large limitation. Against this backdrop, this study, framed by Behavioral Reasoning Theory, utilizes factor analysis and linear regression to create a comprehensive user intention evaluation scale and model. The eight-factor evaluation scale, shaped by user values, includes supporting reasons like usefulness, convenience, growth, and interactivity, and inhibiting factors such as inaccuracy, semantic rigidity, security risk, and cognitive limitation. Attitude serves as an intermediary, positively affected by supporting factors and negatively influenced by inhibiting ones. Core factors impacting user intention are convenience, cognitive limitation, and security risk. This research not only bridges existing gaps but also lays a theoretical foundation for related industries. [ABSTRACT FROM AUTHOR] Copyright of International Journal of Human-Computer Interaction is the property of Taylor & Francis Ltd and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=176427904&site=bsi-live"
"Collaborative optimization with PSO for named entity recognition-based applications.","Peng, Qiaojuan; Luo, Xiong; Shen, Hailun; Huang, Ziyang; Chen, Maojian","Intelligent Data Analysis",="1088467X",,="2023","27","1","103","18","161762711","10.3233/IDA-216483","IOS Press","Article","ARTIFICIAL intelligence; MOBILE communication systems; DATA mining; TELECOMMUNICATION systems; Wireless Telecommunications Carriers (except Satellite); Satellite Telecommunications; MACHINE translating; PARTICLE swarm optimization; RANDOM fields","bi-directional encoder representation from transformers (BERT); collaborative optimization; Named entity recognition (NER); particle swarm optimization (PSO)","Named entity recognition (NER) as a crucial technology is widely used in many application scenarios, including information extraction, information retrieval, text summarization, and machine translation assisted in AI-based smart communication and networking systems. As people pay more and more attention to NER, it has gradually become an independent and important research field. Currently, most of the NER models need to manually adjust their hyper-parameters, which is not only time-consuming and laborious, but also easy to fall into a local optimal situation. To deal with such problem, this paper proposes a machine learning-guided model to achieve NER, where the hyper-parameters of model are automatically adjusted to improve the computational performance. Specifically, the proposed model is implemented by using bi-directional encoder representation from transformers (BERT) and conditional random field (CRF). Meanwhile, the collaborative computing paradigm is also fused in the model, while utilizing the particle swarm optimization (PSO) to automatically search for the best value of hyper-parameters in a collaborative way. The experimental results demonstrate the satisfactory performance of our proposed model. [ABSTRACT FROM AUTHOR] Copyright of Intelligent Data Analysis is the property of IOS Press and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=161762711&site=bsi-live"
"Convolutional Neural Network Algorithm–Based Novel Automatic Text Classification Framework for Construction Accident Reports.","Luo, Xixi; Li, Xinchun; Song, Xuefeng; Liu, Quanlong","Journal of Construction Engineering & Management",="07339364",,="Dec2023","149","12","1","12","173009090","10.1061/JCEMD4.COENG-13523","American Society of Civil Engineers","Article","NATURAL language processing; WORK-related injuries; INDUSTRIAL safety; CONSTRUCTION industry safety; Residential building construction; CONVOLUTIONAL neural networks; DEEP learning; MACHINE learning; AUTOMATIC classification","Accident injury types; Construction safety; Deep learning; Natural language processing (NLP); Text classification","Construction sites remain one of the most hazardous workplaces globally. To improve workplace safety in the construction industry and reduce the personal injuries and socioeconomic impacts resulting from workplace accidents, tacit knowledge containing fundamental causes of accidents or specific contextual factors can be extracted from past accident narrative reports. However, manually analyzing unstructured or semistructured textual data stored in records is a daunting task, and requires the use of automated and intelligent technologies to achieve rapid and accurate knowledge acquisition. Therefore, this paper proposes a text self-classification model based on deep learning natural language processing (NLP) technology for automated classification of construction site accident cases by accident type. First, combined with two statistical measures, mutual information and information entropy, the preprocessed text data were subjected to phrase segmentation to identify more complete and accurate accident precursor information without human intervention. Then a complete multilayer and multisize convolutional neural network (CNN) model was constructed using pretrained Word2Vec word embeddings for text self-classification tasks. Finally, the test results of the CNN classification algorithm were compared with the practical application results of three shallow learning algorithms, and the performance of different types of classification algorithms was evaluated. The results showed that the CNN-based deep learning algorithm developed in this paper demonstrated excellent feature extraction and learning abilities in the task of automatic text classification in the field of NLP. This not only demonstrated that reliable accident prevention knowledge could be obtained from the textual descriptions of construction accidents, but also provided a novel model reference for document archiving and information retrieval. [ABSTRACT FROM AUTHOR] Copyright of Journal of Construction Engineering & Management is the property of American Society of Civil Engineers and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=173009090&site=bsi-live"
"COPS: An improved information retrieval-based bug localization technique using context-aware program simplification.","Yang, Yilin; Wang, Ziyuan; Chen, Zhenyu; Xu, Baowen","Journal of Systems & Software",="01641212",,="Jan2024","207",,"N.PAG","1","173372258","10.1016/j.jss.2023.111868","Elsevier B.V.","Article","PROGRAMMING languages; INFORMATION retrieval; Software Publishers; Software publishers (except video game publishers); DEBUGGING; PYTHON programming language","Bug localization; Information retrieval; Stack trace; Static analysis","Information Retrieval Based Bug Localization (IRBL) techniques are well suited for large-scale software debugging with fewer external dependencies and lower execution costs. However, existing IRBL techniques have several challenges, including localization granularity and applicability. First, existing IRBL techniques have not yet achieved statement-level bug localization. Second, almost all studies are limited to Java-based projects, while their effectiveness for other popular programming languages (e.g., Python) is unknown. The reason for these deficiencies is that existing IRBL techniques mainly rely on conventional NLP techniques to analyze the bug reports and have not yet fully utilized the stack traces attached to the bug reports. To improve the IRBL technique, we propose a context-aware program simplification technique – COPS – that can localize defective statements in suspicious files by analyzing the stack traces in bug reports, enabling statement-level bug localization for Python-based projects. Our experiment is based on 948 bug reports, and the results show that COPS can effectively localize buggy statements. First, compared to the original stack traces, Top@10 is improved by 102.6%, MAP@10 by 56.2%, and MRR@10 by 95.6%. We found that actual buggy code entities are more likely to appear in the first five frames of the stack trace. Second, COPS can achieve equally good localization performance compared to state-of-the-art statement-level bug localization techniques and achieve 92% buggy statement coverage with a full-scope search. Finally, experiments found that the stack trace's first two-thirds of information is more conducive to localizing buggy statements. • A statement-level information retrieval-based bug localization technique. • Setting the retrieval scope can improve the effectiveness of bug localization. • The first two-thirds of the stack trace are more advantageous for bug localization. [ABSTRACT FROM AUTHOR] Copyright of Journal of Systems & Software is the property of Elsevier B.V. and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=173372258&site=bsi-live"
"Dealing with textual noise for robust and effective BERT re-ranking.","Chen, Xuanang; He, Ben; Hui, Kai; Sun, Le; Sun, Yingfei","Information Processing & Management",="03064573",,="Jan2023","60","1","N.PAG","1","160369834","10.1016/j.ipm.2022.103135","Elsevier B.V.","Article","NATURAL language processing; INTERNET searching; INFORMATION retrieval","BERT re-ranking; Ranking model robustness; Text information retrieval; Text perturbation; Textual noise","The pre-trained language models (PLMs), such as BERT, have been successfully employed in two-phases ranking pipeline for information retrieval (IR). Meanwhile, recent studies have reported that BERT model is vulnerable to imperceptible textual perturbations on quite a few natural language processing (NLP) tasks. As for IR tasks, current established BERT re-ranker is mainly trained on large-scale and relatively clean dataset, such as MS MARCO, but actually noisy text is more common in real-world scenarios, such as web search. In addition, the impact of within-document textual noises (perturbations) on retrieval effectiveness remains to be investigated, especially on the ranking quality of BERT re-ranker, considering its contextualized nature. To mitigate this gap, we carry out exploratory experiments on the MS MARCO dataset in this work to examine whether BERT re-ranker can still perform well when ranking text with noise. Unfortunately, we observe non-negligible effectiveness degradation of BERT re-ranker over a total of ten different types of synthetic within-document textual noise. Furthermore, to address the effectiveness losses over textual noise, we propose a novel noise-tolerant model, De-Ranker, which is learned by minimizing the distance between the noisy text and its original clean version. Our evaluation on the MS MARCO and TREC 2019–2020 DL datasets demonstrates that De-Ranker can deal with synthetic textual noise more effectively, with 3%–4% performance improvement over vanilla BERT re-ranker. Meanwhile, extensive zero-shot transfer experiments on a total of 18 widely-used IR datasets show that De-Ranker can not only tackle natural noise in real-world text, but also achieve 1.32% improvement on average in terms of cross-domain generalization ability on the BEIR benchmark. • The first investigation into the effects of within-document textual noise on BERT re-ranker. • Effectiveness of BERT re-ranker declines when coming across textual noises. • Synthetic noise injected into MS MARCO can be useful to enhance BERT re-ranker. • De-Ranker can effectively deal with textual noise by learning a noise-invariant relevance estimation. [ABSTRACT FROM AUTHOR] Copyright of Information Processing & Management is the property of Pergamon Press - An Imprint of Elsevier Science and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=160369834&site=bsi-live"
"ELCA: Enhanced boundary location for Chinese named entity recognition via contextual association.","Wang, Yizhao; Mao, Shun; Jiang, Yuncheng","Intelligent Data Analysis",="1088467X",,="2024","28","4","973","18","178739802","10.3233/IDA-230383","IOS Press","Article","NATURAL language processing; INFORMATION retrieval; PROBLEM solving; CHINESE language; AMBIGUITY","Lattice-LSTM; Nested Chinese NER; NLP","Named Entity Recognition (NER) is a fundamental task that aids in the completion of other tasks such as text understanding, information retrieval and question answering in Natural Language Processing (NLP). In recent years, the use of a mix of character-word structure and dictionary information for Chinese NER has been demonstrated to be effective. As a representative of hybrid models, Lattice-LSTM has obtained better benchmarking results in several publicly available Chinese NER datasets. However, Lattice-LSTM does not address the issue of long-distance entities or the detection of several entities with the same character. At the same time, the ambiguity of entity boundary information also leads to a decrease in the accuracy of embedding NER. This paper proposes ELCA: Enhanced Boundary Location for Chinese Named Entity Recognition Via Contextual Association, a method that solves the problem of long-distance dependent entities by using sentence-level position information. At the same time, it uses adaptive word convolution to overcome the problem of several entities sharing the same character. ELCA achieves the state-of-the-art outcomes in Chinese Word Segmentation and Chinese NER. [ABSTRACT FROM AUTHOR] Copyright of Intelligent Data Analysis is the property of IOS Press and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=178739802&site=bsi-live"
"Exploiting salient semantic analysis for information retrieval.","Luo, Jing; Meng, Bo; Quan, Changqin; Tu, Xinhui","Enterprise Information Systems",="17517575",,="Dec2016","10","9","959","11","118173821","10.1080/17517575.2015.1080301","Taylor & Francis Ltd","Article","INFORMATION retrieval; NATURAL language processing; TEXT Retrieval Conference; LANGUAGE & languages; WIKIPEDIA","document model; Information retrieval; language model; salient semantic analysis; Wikipedia","Recently, many Wikipedia-based methods have been proposed to improve the performance of different natural language processing (NLP) tasks, such as semantic relatedness computation, text classification and information retrieval. Among these methods, salient semantic analysis (SSA) has been proven to be an effective way to generate conceptual representation for words or documents. However, its feasibility and effectiveness in information retrieval is mostly unknown. In this paper, we study how to efficiently use SSA to improve the information retrieval performance, and propose a SSA-based retrieval method under the language model framework. First, SSA model is adopted to build conceptual representations for documents and queries. Then, these conceptual representations and the bag-of-words (BOW) representations can be used in combination to estimate the language models of queries and documents. The proposed method is evaluated on several standard text retrieval conference (TREC) collections. Experiment results on standard TREC collections show the proposed models consistently outperform the existing Wikipedia-based retrieval methods. [ABSTRACT FROM AUTHOR] Copyright of Enterprise Information Systems is the property of Taylor & Francis Ltd and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=118173821&site=bsi-live"
"Exploring the applications of natural language processing and language models for production, planning, and control activities of SMEs in industry 4.0: a systematic literature review.","Mathieu, Bourdin; Anas, Neumann; Thomas, Paviot; Robert, Pellerin; Samir, Lamouri","Journal of Intelligent Manufacturing",="09565515",,="Nov2024",,,"1",,"180845148","10.1007/s10845-024-02509-w","Springer Nature","Article","SMALL business; PROGRAMMING languages; NATURAL language processing; Software publishers (except video game publishers); Software Publishers; LANGUAGE models; MACHINE learning; RESEARCH questions","Industry 4.0; Language models; Machine learning; Natural language processing; SMEs","In the wake of the prominence of language models such as ChatGPT/GPT4 and the emergence of various Natural Language Processing (NLP) approaches, there has been growing interest in their applications. However, a gap exists in scientific documentation regarding Small and Medium Enterprises (SMEs) within the industrial sector. This paper addresses this gap. This is the first systematic review of the literature associated with the context of NLP in industry. Through five research questions, it provides an overview of NLP applications, goals, technical solutions, obstacles, and applicability to SMEs, which is useful for both researchers and manufacturers. Following the PRISMA 2020 methodology, this study reveals a lack of literature addressing the use of NLP in industrial SMEs. The findings suggest that NLP is predominantly applied in specific industrial domains, including design, process monitoring, and maintenance. NLP applications mainly aim to enhance operational performance, notably in support functions like maintenance, safety, and continuous improvement. Practical implementations include automatic data analysis, similarity searches, information retrieval, and the conversion of raw text into standardized data. When looking at the technical solutions implemented, the paper demonstrates a strong diversity in the encountered algorithmic approaches. Challenges include remaining up-to-date, scaling, addressing low-quality or insufficient data issues, and navigating domain- or operator-specific vocabulary. In particular, maintaining up-to-date data presents a critical challenge for NLP applications but with limited identified solutions. Finally, the study indicates that only a fraction of the proposed NLP algorithmic solutions may apply to SMEs because of a lack of resources, expertise, and standardized procedures. [ABSTRACT FROM AUTHOR] Copyright of Journal of Intelligent Manufacturing is the property of Springer Nature and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=180845148&site=bsi-live"
"Generating keyphrases for readers: A controllable keyphrase generation framework.","Jiang, Yi; Meng, Rui; Huang, Yong; Lu, Wei; Liu, Jiawei","Journal of the Association for Information Science & Technology",="23301635",,="Jul2023","74","7","759","16","164116223","10.1002/asi.24749","Wiley-Blackwell","Article","NATURAL language processing; TASK performance; INFORMATION retrieval; ACCESS to information; INFORMATION science; DESCRIPTIVE statistics; RESEARCH funding; ABSTRACTING & indexing services; INFORMATION technology; Internet Publishing and Broadcasting and Web Search Portals; SEMANTICS; CONCEPTUAL structures; READING; BLOGS",,"With the wide application of keyphrases in many Information Retrieval (IR) and Natural Language Processing (NLP) tasks, automatic keyphrase prediction has been emerging. However, these statistically important phrases are contributing increasingly less to the related tasks because the end‐to‐end learning mechanism enables models to learn the important semantic information of the text directly. Similarly, keyphrases are of little help for readers to quickly grasp the paper's main idea because the relationship between the keyphrase and the paper is not explicit to readers. Therefore, we propose to generate keyphrases with specific functions for readers to bridge the semantic gap between them and the information producers, and verify the effectiveness of the keyphrase function for assisting users' comprehension with a user experiment. A controllable keyphrase generation framework (the CKPG) that uses the keyphrase function as a control code to generate categorized keyphrases is proposed and implemented based on Transformer, BART, and T5, respectively. For the Computer Science domain, the Macro‐avgs of P@5, R@5, and F1@5 on the Paper with Code dataset are up to 0.680, 0.535, and 0.558, respectively. Our experimental results indicate the effectiveness of the CKPG models. [ABSTRACT FROM AUTHOR] Copyright of Journal of the Association for Information Science & Technology is the property of Wiley-Blackwell and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=164116223&site=bsi-live"
"Graph collaborative filtering-based bug triaging.","Dai, Jie; Li, Qingshan; Xue, Hui; Luo, Zhao; Wang, Yinglin; Zhan, Siyuan","Journal of Systems & Software",="01641212",,="Jun2023","200",,"N.PAG","1","162895206","10.1016/j.jss.2023.111667","Elsevier B.V.","Article","SOFTWARE engineering; SOFTWARE engineers; ARTIFICIAL intelligence; NATURAL language processing; BIPARTITE graphs; NATURAL languages; TEMPORAL databases; FILTERS & filtration","Bug triaging; Deep graph learning; Graph collaborative filtering; Software reliability engineering","Issue tracking systems are widely used for collecting bug reports. A target of intelligent software engineering is to automate assigning bugs to appropriate developers. Recently, the momentum of artificial intelligence has brought many successful studies that triage bugs by classifying their reports with NLP-based methods. Some studies also try to introduce context information to represent developers. Nevertheless, they take a fundamental assumption that developers and bugs, closely related entities in real-world scenarios, should be modeled independently. To capture the bug-developer correlations in bug triaging activities, we propose a Graph Collaborative filtering-based Bug Triaging framework: (1) bug-developer correlations are modeled as a bipartite graph; (2) natural language processing-based pre-training is implemented on bug reports to initialize bug nodes; (3) spatial–temporal graph convolution strategy is designed to learn the representation of developer nodes; (4) information retrieval-based classifier is proposed to match bugs and developers. Extensive experiments across mainstream datasets show the competence of our GCBT. Moreover, We believe that GCBT could generally benefit the modeling of correlations in other software engineering scenarios. • Bug-developer correlations are modeled as a bipartite graph. • Natural language processing-based pre-training is implemented on bug reports to initialize bug nodes. • Spatial–temporal graph convolution strategy is designed to learn the representation of developer nodes. • Information retrieval-based classifier is proposed to match bugs and developers. • Extensive experiments across mainstream datasets show the competence of our GCBT. [ABSTRACT FROM AUTHOR] Copyright of Journal of Systems & Software is the property of Elsevier B.V. and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=162895206&site=bsi-live"
"Human-machine collaboration in online customer service – a long-term feedback-based approach.","Graef, Roland; Klier, Mathias; Kluge, Kilian; Zolitschka, Jan Felix","Electronic Markets",="10196781",,="Jun2021","31","2","319","23","151526035","10.1007/s12525-020-00420-9","Springer Nature","Article",,"Human-machine collaboration; Long-term feedback; Online customer service; Textual case-based reasoning","The rising expectations of customers have considerably contributed to the need for automated approaches supporting employees in online customer service. Since automated approaches still struggle to meet the challenge to fully grasp the semantics of texts, hybrid approaches combining the complementary strengths of human and artificial intelligence show great potential for assisting employees. While research in Case-Based Reasoning (CBR) already provides well-established approaches, they do not fully exploit the potential of CBR as hybrid intelligence. Against this background, we follow a design-oriented approach and develop an adapted textual CBR cycle that integrates employees' feedback on semantic similarity, which is collected during the Reuse phase, into the Retrieve phase by means of long-term feedback methods from information retrieval. Using a real-world data set, we demonstrate the practical applicability and evaluate our approach regarding performance in online customer service. Our novel approach surpasses human-based, machine-based, and hybrid approaches in terms of effectiveness due to a refined retrieval of semantically similar customer problems. It is further favorable regarding efficiency, reducing the average time required to solve a customer problem. [ABSTRACT FROM AUTHOR] Copyright of Electronic Markets is the property of Springer Nature and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=151526035&site=bsi-live"
"Improving accountability in recommender systems research through reproducibility.","Bellogín, Alejandro; Said, Alan","User Modeling & User-Adapted Interaction",="09241868",,="Nov2021","31","5","941","37","154247748","10.1007/s11257-021-09302-x","Springer Nature","Article","RECOMMENDER systems; INFORMATION retrieval; ARTIFICIAL intelligence; DECISION making; HUMAN-computer interaction; REPRODUCIBLE research; MACHINE learning","Accountability; Evaluation; Recommender systems; Reproducibility","Reproducibility is a key requirement for scientific progress. It allows the reproduction of the works of others, and, as a consequence, to fully trust the reported claims and results. In this work, we argue that, by facilitating reproducibility of recommender systems experimentation, we indirectly address the issues of accountability and transparency in recommender systems research from the perspectives of practitioners, designers, and engineers aiming to assess the capabilities of published research works. These issues have become increasingly prevalent in recent literature. Reasons for this include societal movements around intelligent systems and artificial intelligence striving toward fair and objective use of human behavioral data (as in Machine Learning, Information Retrieval, or Human–Computer Interaction). Society has grown to expect explanations and transparency standards regarding the underlying algorithms making automated decisions for and around us. This work surveys existing definitions of these concepts and proposes a coherent terminology for recommender systems research, with the goal to connect reproducibility to accountability. We achieve this by introducing several guidelines and steps that lead to reproducible and, hence, accountable experimental workflows and research. We additionally analyze several instantiations of recommender system implementations available in the literature and discuss the extent to which they fit in the introduced framework. With this work, we aim to shed light on this important problem and facilitate progress in the field by increasing the accountability of research. [ABSTRACT FROM AUTHOR] Copyright of User Modeling & User-Adapted Interaction is the property of Springer Nature and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=154247748&site=bsi-live"
"In the pursuit of semantic similarity for literature on microbial transcriptional regulation.","Lithgow-Serrano, Oscar; Collado-Vides, Julio; Pinto, David; Singh, Vivek","Journal of Intelligent & Fuzzy Systems",="10641246",,="2019","36","5","4777","10","136448666","10.3233/JIFS-179026","IOS Press","Article","NATURAL language processing; SCIENTIFIC literature; RESEMBLANCE (Philosophy)","Natural Language Processing; Semantic Textual Similarity","The constant increase in the production of scientific literature is making it very difficult for experts to keep up to date with the state-of-the-art knowledge in their fields. The use of Natural Language Processing (NLP) is becoming a necessary aid to tackle this challenge. In the NLP field, the task of measuring semantic similarity between two sentences plays a vital role. It is a cornerstone for tasks like Q&A, Information Retrieval, Automatic Summarization, etc., and it is a crucial element in the ultimate goal of computers being able to decode what is conveyed in human language expression. Measuring Semantic Similarity (SS) in short texts has specific challenges. Because there are fewer words to be compared, the meaning contribution of each word is more relevant, and it is important to take into account the syntax's contribution to the composed meaning. In addition, the highly specific and specialized vocabulary — Microbial Transcriptional-Regulation—implies the lack of massive training resources. Our approach has been to use an ensemble of similarity metrics including string, distributional, and knowledge-based metric and to combine the results of such analyses. We have trained and tested these methods in a similarity corpus developed in-house. The task has proved very challenging, and the ensemble strategy has proved to be a good approach. Even though there is still much room for improvement in the precision of our methods concerning the human evaluation, we have managed to improve them reaching a strong correlation (ρ = 0.700). [ABSTRACT FROM AUTHOR] Copyright of Journal of Intelligent & Fuzzy Systems is the property of IOS Press and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=136448666&site=bsi-live"
"Industry Commons: an ecosystem approach to horizontal enablers for sustainable cross-domain industrial innovation (a positioning paper).","Magas, Michela; Kiritsis, Dimitris","International Journal of Production Research",="00207543",,="Jan2022","60","2","479","14","155381396","10.1080/00207543.2021.1989514","Taylor & Francis Ltd","Article","MANUFACTURING processes; INTELLECTUAL property; SUPPLY chain management; SOCIAL responsibility of business; Industrial Process Furnace and Oven Manufacturing; Instruments and Related Products Manufacturing for Measuring, Displaying, and Controlling Industrial Process Variables; GRAPHICAL user interfaces; ECOSYSTEMS; FOOD chains; DIGITAL music","Closed-Loop Lifecycle Management; Enterprise Integration; Industry Commons; Intertwined Supply Networks; Ontology Ecosystem; Trusted Data Sharing","This paper introduces the background, concept and definition of the Industry Commons. It initiates a discussion on the positioning of the Industry Commons Ecosystem (ICE) with respect to current research directions in advanced manufacturing and production systems that shape advances in engineering and technology, novel business models and innovation breakthroughs. The potential value of data sharing across industrial domains is estimated at over $100 billion, particularly in view of optimising manufacturing processes. Data sharing across domains however faces a series of well-documented challenges associated with the lack of semantic interoperability and related standards, management of trust and sustainability. Solving bottlenecks in data sharing requires a systemic approach to data management, which can account for all aspects of data use, levels of application, attribution and dynamic exchanges. In this paper we propose a high-level ecosystem approach that integrates societal values with digital affordances of industry's cognitive-assisted processes, remote interfacing, hybrid applications and large-scale value networks. Early development of an Ontology Commons EcoSystem (OCES) is presented as the key enabling framework for Industry Commons interoperability and a series of enabling frameworks form the basis of future research directions in Trusted Data Sharing and Closed-Loop Lifecycle Management for greater sustainability. Abbreviations: AI – Artificial Intelligence; AIOTI – Alliance of Internet-of-Things Innovation; ALM – Asset Lifecycle Management; ALO – Application-Level Ontology; AP – Application Protocol; API – Application Programming Interface; B2B – Business-to-Business; B2C – Business-to-Customer; CDE – Cross-Domain Ecosystem; CDEI – Cross-Domain Ecosystem Interoperability; CL2M – Closed-Loop Lifecycle Management; CNO – Collaborative Networked Organisations; CPS – Cyber-Physical Systems; CSR – Corporate Social Responsibility; DLO – Domain-Level Ontology; DLT – Distributed Ledger Technology; EM – Enterprise Modelling; FAIR – Findable, Accessible, Interoperable and Reusable; GUI – Graphical User Interface; ICE, Industry Commons Ecosystem; IOF – Industrial Ontology Foundry; IP – Intellectual Property; IPR – Intellectual Property Rights; ISN – Intertwined Supply Network; MIR – Music Information Retrieval; MLO – Middle-Level Ontology; MO – Meta-Ontology; OCES – Ontology Commons EcoSystem; PI – Physical Internet; PLM – Product Lifecycle Management; ROI – Return-on-Investment; SC – Supply Chain; SCM – Supply Chain Management; SOS – System-of-Systems; TDS – Trusted Data Sharing; TLO – Top-Level Ontology; TRO – Top Reference Ontology; TUI – Tangible User Interface. [ABSTRACT FROM AUTHOR] Copyright of International Journal of Production Research is the property of Taylor & Francis Ltd and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=155381396&site=bsi-live"
"Integrating large language models and generative artificial intelligence tools into information literacy instruction.","Carroll, Alexander J.; Borycz, Joshua","Journal of Academic Librarianship",="00991333",,="Jul2024","50","4","N.PAG","1","177854578","10.1016/j.acalib.2024.102899","Elsevier B.V.","Article","INFORMATION science; LANGUAGE & languages; GENERATIVE artificial intelligence; INFORMATION literacy; STEM education; ENGINEERING education","Critical thinking; Generative artificial intelligence; Information literacy; Information retrieval; Large language models","Generative artificial intelligence (AI) and large language models (LLMs) have induced a mixture of excitement and panic among educators. However, there is a lack of consensus over how much experience science and engineering students have with using these tools for research-related tasks. Likewise, it is not yet known how educators and information professionals can leverage these tools to teach students strategies for information retrieval and knowledge synthesis. This study assesses the extent of students' use of AI tools in research-related tasks and if information literacy instruction could impact their perception of these tools. Responses to Likert-scale questions indicate that many students did not have extensive experience using LLMs for research-related purposes prior to the information literacy sessions. However, after participating in a didactic lecture and discussion with an engineering librarian that explored how to use these tools effectively and responsibly, many students reported viewing these tools as potentially useful for future assignments. Student responses to open-response questions suggest that librarian-led information literacy training can assist students in developing more sophisticated understandings of the limitations and use cases for artificial intelligence in inquiry-based coursework. [ABSTRACT FROM AUTHOR] Copyright of Journal of Academic Librarianship is the property of Elsevier B.V. and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=177854578&site=bsi-live"
"Issue Information.",,"Journal of the Association for Information Science & Technology",="23301635",,="Oct2024","75","10","1023","2","180426736","10.1002/asi.24790","Wiley-Blackwell","Article",,,"The article focuses on various aspects of building healthier information ecosystems including the role of voice assistants in health information seeking, strategies for inclusive global scholarly communication, and the impact of artificial intelligence on everyday information retrieval.","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=180426736&site=bsi-live"
"Knowledge powered by artificial intelligence.","Pichman, Brian","Information Services & Use",="01675265",,="Nov2024",,,"1",,"180869637","10.1177/18758789241299017","IOS Press","Article",,"AI ethics; bias reduction; customer support AI; generative AI; healthcare AI; knowledge forecasting; knowledge management; large language models; legacy systems; multilingual support; personalized information retrieval; RAG; real-time collaboration; Retrieval Augmented Generation systems","Generative Artificial Intelligence (GenAI) has revolutionized knowledge management, offering unprecedented capabilities for creating, proofing, summarizing, and evaluating documentation. This paper explores how AI, particularly large language models (LLMs), and Retrieval Augmented Generation (RAG) systems, can streamline the development of knowledge articles while addressing ethical concerns such as data ownership and bias. We examine practical applications, including real-time collaboration, multilingual support, personalized information retrieval, and automated knowledge forecasting. Additionally, we explore AI’s role in bridging legacy systems, reducing biases, and enhancing decision-making. Ultimately, AI extends beyond generating content, shaping a more efficient, inclusive, and innovative approach to knowledge management. This article is based upon a presentation given at the 2024 NISO Plus Conference that was held in Baltimore, MD, USA, February 13–14, 2024. [ABSTRACT FROM AUTHOR] Copyright of Information Services & Use is the property of IOS Press and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=180869637&site=bsi-live"
"LARGE LANGUAGE MODELS FOR TEXT SUMMARIZATION: A COMPREHENSIVE STUDY.","Kumar, Jeetendra","Pranjana: The Journal of Management Awareness",="09719997",,="Jan-Dec2023","26","1/2","113","12","180940535","10.5958/0974-0945.2023.00011.0","INMANTEC: Integrated Academy of Management & Technology","Article",,"Fine-Tuning; Large Language Model; Text Summarization; Transfer Learning","In Natural Language Processing (NLP), Large Language Models (LLMs) like GPT-4 are revolutionizing text-based applications. They enable more intuitive and human-like interactions, significantly enhancing machine understanding and generation of natural language. These LLMs, powered by deep learning, have ushered in a new era of automated text summarization, which is vital for information retrieval and understanding. With the exponential growth of internet textual data, there is a growing need for efficient, accurate, and scalable text summarization methods. Large Language Models (LLMs) are ushering in a new era in Natural Language Processing (NLP), with their ability to autonomously distill key insights from vast text corpora into succinct, intelligible summaries. This in-depth analysis delves into the pivotal function of LLMs in advancing the art of text summarization, making complex information readily understandable. It delves into the evolution of NLP, the development of LLMs, their architectural intricacies, and the challenges and opportunities they bring to text summarization. By the end of this exploration, readers will have a deeper understanding of these models, their capabilities, limitations, and the profound impact they can have across various applications, including news aggregation and research paper condensation. [ABSTRACT FROM AUTHOR] Copyright of Pranjana: The Journal of Management Awareness is the property of INMANTEC: Integrated Academy of Management & Technology and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=180940535&site=bsi-live"
"Leveraging AI-based Decision Support for Opportunity Analysis.","Groher, Wolfgang; Rademacher, Friedrich-Wilhelm; Csillaghy, André","Technology Innovation Management Review",="19270321",,="Dec2019","9","12","29","7","141074992","10.22215/timreview/1289","Carleton University, Talent First Network, Technology Innovation Management Review","Article","ARTIFICIAL intelligence; INFORMATION retrieval; DESIGN science; INFORMATION processing; LATENT semantic analysis; CONCEPTUAL models","artificial intelligence; decision-making; design science; environmental scanning; front-end of innovation; information processing; information retrieval; innovation search field; latent semantic indexing; opportunity","The dynamics and speed of change in corporate environments have increased. At the front-end of innovation, firms are challenged to evaluate growing amounts of information within shorter time frames in order to stay competitive. Either they spend significant time on structured data analysis, at the risk of delayed market launch, or they follow their intuition, at the risk of not meeting market trends. Both scenarios constitute a significant risk for a firm's continued existence.Motivated by this, a conceptual model is presented in this paper that aims at remediating these risks. Grounded on design science methodology, it concentrates on previous assessments of innovation search fields. These innovation search fields assist in environmental scanning and lay the foundation for deciding which opportunities to pursue. The model applies a novel AI-based approach, which draws on natural language processing and information retrieval. To provide decision support, the approach includes market-, technology-, and firm-related criteria. This allows us to replace intuitive decision-making by fact-based considerations. In addition, an often-iterative approach for environmental scanning is replaced by a more straightforward process. Early testing of the conceptual model has shown results of increased quality and speed of decision-making. Further testing and feedback is still required to enhance and calibrate the AI-functionality. Applied in business environments, the approach can contribute to remediate fuzziness in early front-end activities, thus helping direct innovation managers to ""do the right things"". [ABSTRACT FROM AUTHOR] Copyright of Technology Innovation Management Review is the property of Carleton University, Talent First Network, Technology Innovation Management Review and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=141074992&site=bsi-live"
"Modeling multiple interactions with a Markov random field in query expansion for session search.","Li, Jingfei; Zhao, Xiaozhao; Zhang, Peng; Song, Dawei","Computational Intelligence",="08247935",,="Feb2018","34","1","345","18","128227540","10.1111/coin.12154","Wiley-Blackwell","Article","MARKOV processes; SEARCH engines; ARTIFICIAL intelligence; INFORMATION retrieval; MARKOV random fields; QUERY (Information retrieval system)","Markov random field; multiple interactions; query expansion; session search","Abstract: How to automatically understand and answer users' questions (eg, queries issued to a search engine) expressed with natural language has become an important yet difficult problem across the research fields of information retrieval and artificial intelligence. In a typical interactive Web search scenario, namely, session search, to obtain relevant information, the user usually interacts with the search engine for several rounds in the forms of, eg, query reformulations, clicks, and skips. These interactions are usually mixed and intertwined with each other in a complex way. For the ideal goal, an intelligent search engine can be seen as an artificial intelligence agent that is able to infer what information the user needs from these interactions. However, there still exists a big gap between the current state of the art and this goal. In this paper, in order to bridge the gap, we propose a Markov random field–based approach to capture dependence relations among interactions, queries, and clicked documents for automatic query expansion (as a way of inferring the information needs of the user). An extensive empirical evaluation is conducted on large‐scale web search data sets, and the results demonstrate the effectiveness of our proposed models. [ABSTRACT FROM AUTHOR] Copyright of Computational Intelligence is the property of Wiley-Blackwell and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=128227540&site=bsi-live"
"Multilingual Information Access (MLIA) Tools on Google and WorldCat: Bi/Multilingual University Students' Experience and Perceptions.","Nzomo, Peggy; Vaughan, Liwen; Ajiferuke, Isola; McKenzie, Pam","Journal of Library Administration",="01930826",,="Nov/Dec2019","59","8","831","23","139211693","10.1080/01930826.2019.1661750","Taylor & Francis Ltd","Article","NATURAL language processing; GOOGLE Inc.; CROSS-language information retrieval; COLLEGE students; NATIVE language","bi/multilingual students; cross language information retrieval (CLIR); Google; information retrieval experiment; information searching behavior; multilingual information access (MLIA) tools; multilingual information retrieval (MLIR); personalized multilingual information retrieval (PMLIR) models; WorldCat","This article reports on the results of an exploratory user-centered study that examined how technological advancements in natural language processing (NLP) such as the availability of multilingual information access (MLIA) tools impact the information searching behavior of bi/multilingual academic users. Thirty-one bi/multilingual students participated in a controlled lab-based user experiment in which they carried out two assigned tasks each on Google and WorldCat for a total of four tasks, and then completed a post experiment questionnaire. The captures from the experiment showed 86.7% of the participants using multilingual information access tools. Further analyses of the captures also showed that participants were more likely to use MLIA tools when the instructions for the task were stated in their native language. An independent samples t-test revealed that participants spent less time on their searches when they used MLIA tools. The study revealed considerable diversity in the information searching behavior of the participants, even within the same pair of languages, and even for the same user. Diversity was noted for instance, on which tasks MLIA tools were used and in how these tools were used. User-centered designed, personalized multilingual information retrieval (PMLIR) models could hold promise for best representing the information searching behavior of bi/multilingual users. [ABSTRACT FROM AUTHOR] Copyright of Journal of Library Administration is the property of Taylor & Francis Ltd and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=139211693&site=bsi-live"
"Natural language processing for aviation safety reports: From classification to interactive analysis.","Tanguy, Ludovic; Tulechki, Nikola; Urieli, Assaf; Hermann, Eric; Raynal, Céline","Computers in Industry",="01663615",,="May2016","78",,"80","16","114052306","10.1016/j.compind.2015.09.005","Elsevier B.V.","Article","AIRLINE industry; EUROPEAN Aviation Safety Agency; INTERNATIONAL Civil Aviation Organization; Scheduled air transportation; Scheduled Passenger Air Transportation; FLIGHT; COMPUTATIONAL linguistics; SAFETY","Aviation; Document classification; NLP; Safety reports; Text mining","In this paper we describe the different NLP techniques designed and used in collaboration between the CLLE-ERSS research laboratory and the CFH/Safety Data company to manage and analyse aviation incident reports. These reports are written every time anything abnormal occurs during a civil air flight. Although most of them relate routine problems, they are a valuable source of information about possible sources of greater danger. These texts are written in plain language, show a wide range of linguistic variation (telegraphic style overcrowded by acronyms or standard prose) and exist in different languages, even for a single company/country (although our main focus is on English and French). In addition to their variety, their sheer quantity (e.g. 600/month for a large airline company) clearly requires the use of advanced NLP and text mining techniques in order to extract useful information from them. Although this context and objectives seem to indicate that standard NLP techniques can be applied in a straightforward manner, innovative techniques are required to handle the specifics of aviation report text and the complex classification systems. We present several tools that aim at a better access to this data (classification and information retrieval), and help aviation safety experts in their analyses (data/text mining and interactive analysis). Some of these tools are currently in test or in use both at the national and international levels, by airline companies as well as by regulation authorities (DGAC, 1 1 Direction Générale de l’Aviation Civile. EASA, 2 2 European Aviation Safety Agency. ICAO 3 3 International Civil Aviation Organization. ). [ABSTRACT FROM AUTHOR] Copyright of Computers in Industry is the property of Elsevier B.V. and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=114052306&site=bsi-live"
"Past, current and future trends in enterprise architecture—A view beyond the horizon.","Gampfer, Fabian; Jürgens, Andreas; Müller, Markus; Buchkremer, Rüdiger","Computers in Industry",="01663615",,="Sep2018","100",,"70","15","129923122","10.1016/j.compind.2018.03.006","Elsevier B.V.","Article","Data Processing, Hosting, and Related Services; TEXT mining; META-analysis; TREND analysis; CLOUD computing; ARCHITECTS; COMPUTER network resources","Enterprise architecture; Systematic review; Text mining; Trend analysis","Since its introduction in the late nineteen eighties, the discipline of Enterprise Architecture (EA) has evolved into a well-known practice of managing information systems in alignment with business interests. The evolution of the discipline is reflected in the many available scientific publications. Within a timeframe of three decades, we identify approximately 4000 journal articles and conference papers of which enterprise architecture is a major topic. We conduct a holistic, systematic literature review using artificial intelligence technologies such as information retrieval, text mining and supervised learning, side-by-side with manually reading of many relevant articles. For the first time, we present a holistic historical overview of the scientific development of the discipline. We describe the current focus of enterprise architecture and make suggestions for future publications and conferences using predictive analytics. As a major result of our analysis, we find that the focus of EA research has shifted from understanding EA in the early years to managing EA today. Furthermore, we identify and investigate several current EA trend topics: We find Cloud Computing to be the trend with the strongest impact on EA and predict that this will be the case until 2020. According to our forecast, the Internet of Things will be the trend with the strongest growth in its impact on EA. Moreover, based on a comparison with the Gartner Hype Cycle, we observe a discrepancy between EA trends in academic work versus practical experiences, which presents a starting point for future research. [ABSTRACT FROM AUTHOR] Copyright of Computers in Industry is the property of Elsevier B.V. and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=129923122&site=bsi-live"
"PCAO2: an ontology for integration of prostate cancer associated genotypic, phenotypic and lifestyle data.","Yu, Chunjiang; Zong, Hui; Chen, Yalan; Zhou, Yibin; Liu, Xingyun; Lin, Yuxin; Li, Jiakun; Zheng, Xiaonan; Min, Hua; Shen, Bairong","Briefings in Bioinformatics",="14675463",,="May2024","25","3","1","10","177375762","10.1093/bib/bbae136","Oxford University Press / USA","Article","INFORMATION storage & retrieval systems; ONTOLOGIES (Information retrieval); PROSTATE cancer; KNOWLEDGE graphs; GENOTYPES; ONTOLOGY; DEEP learning","deep phenotyping; knowledge graph; knowledge representation; ontology; prostate cancer","Disease ontologies facilitate the semantic organization and representation of domain-specific knowledge. In the case of prostate cancer (PCa), large volumes of research results and clinical data have been accumulated and needed to be standardized for sharing and translational researches. A formal representation of PCa-associated knowledge will be essential to the diverse data standardization, data sharing and the future knowledge graph extraction, deep phenotyping and explainable artificial intelligence developing. In this study, we constructed an updated PCa ontology (PCAO2) based on the ontology development life cycle. An online information retrieval system was designed to ensure the usability of the ontology. The PCAO2 with a subclass-based taxonomic hierarchy covers the major biomedical concepts for PCa-associated genotypic, phenotypic and lifestyle data. The current version of the PCAO2 contains 633 concepts organized under three biomedical viewpoints, namely, epidemiology, diagnosis and treatment. These concepts are enriched by the addition of definition, synonym, relationship and reference. For the precision diagnosis and treatment, the PCa-associated genes and lifestyles are integrated in the viewpoint of epidemiological aspects of PCa. PCAO2 provides a standardized and systematized semantic framework for studying large amounts of heterogeneous PCa data and knowledge, which can be further, edited and enriched by the scientific community. The PCAO2 is freely available at https://bioportal.bioontology.org/ontologies/PCAO , http://pcaontology.net/ and http://pcaontology.net/mobile/. [ABSTRACT FROM AUTHOR] Copyright of Briefings in Bioinformatics is the property of Oxford University Press / USA and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=177375762&site=bsi-live"
"Personalized Smart Diet Assistance System in Health Care Prosperity with AI and AR.","Rao, Kodepogu Koteswara; Shanti, Chavala; Rao, Annam Jagadeeswara; Babu, Songa Bosu; Kumari, Gaddala Lalitha; Surekha, Yalamanchili","Ingénierie des Systèmes d'Information",="16331311",,="Apr2022","27","2","267","8","156885409","10.18280/isi.270210","International Information & Engineering Technology Association (IIETA)","Article","MEDICAL care; COVID-19 pandemic; FOOD consumption","AI; augmented reality; smart diet; transmissible diseases; WHO","Health care prosperity is the most challenging task for human being in the present dangerous COVID scenario and the discovery proposes an augmented reality based personalized smart diet assistance system which provides diet recommendations, appropriate time, type, quantity and method of consumption of a food item diet based on user health parameters based on location and event activities. The augmented reality based system comprises a user data input, an image processing, food consumption assistance, transmissible disease information retrieval and diet planning modules. The system incorporates an AI based camera to scan a food item before or after cooking and utilizes augmented reality to indicate the nutritional information. The proposed system provides personalized diet recommendations to the user based on personal data such as height, weight, existing medical conditions and thereof of a user. The system retrieves existing transmissible diseases data from world health organizations and data from news articles about any viral infections or diseases to suggest immunity boosting foods to the user to thereby safeguard the user against such diseases or infections. [ABSTRACT FROM AUTHOR] Copyright of Ingénierie des Systèmes d'Information is the property of International Information & Engineering Technology Association (IIETA) and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=156885409&site=bsi-live"
"Phonetic-Based Forward Online Transliteration Tool from English to Tamil Language.","Anbukkarasi, S.; Elangovan, D.; Periyasamy, Jayalakshmi; Sathishkumar, V. E.; Dharinya, S. Sree; Kumar, M. Sandeep; Prabhu, J.","International Journal of Reliability, Quality & Safety Engineering",="02185393",,="Jun2023","30","3","1","14","164117546","10.1142/S021853932350002X","World Scientific Publishing Company","Article","NATURAL language processing; INDIA; MACHINE translating; TRANSLITERATION; ENGLISH language; JAPANESE language; NATURAL languages","artificial intelligence; E-learning; named entity recognition; Natural Language Processing; Tamil; transliteration","Transliteration is the process of mapping the character of one language to the character of some other language based on its phonetics. India is very much diverse in languages where people speak different languages. Though they speak different languages, it might be difficult for them to read the script of those many languages. In a situation like this, transliteration process plays a major role. It helps in various Natural Language Processing applications such as Information retrieval, Machine translation, Speech recognition. These are NLP applications which make the computer understand the natural language as to how human being interprets. It helps in translating technical terms and proper names from one language to another language. Moreover, transliteration works have been carried out in languages such as Japanese, Chinese and English. But when considering Indian languages, especially Tamil language, very few recognizable works have been carried out. In this paper, transliteration process is carried out on Unicode Tamil characters. The phonetics-based forward list processing is implemented for transliterating from English language to Tamil language which yields promising results. [ABSTRACT FROM AUTHOR] Copyright of International Journal of Reliability, Quality & Safety Engineering is the property of World Scientific Publishing Company and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=164117546&site=bsi-live"
"RBNN application and simulation in big data set classification.","Zhang, Qin; Wilson, Fred; Balas, Valentina E.; Hong, Jer Lang; Gu, Jason; Lin, Tsung-Chih","Journal of Intelligent & Fuzzy Systems",="10641246",,="2019","37","4","4467","9","139366237","10.3233/JIFS-179279","IOS Press","Article","BIG data; NATURAL language processing; DIMENSION reduction (Statistics); TEXT mining; RADIAL basis functions; PATTERN recognition systems; CLASSIFICATION algorithms; CLASSIFICATION","Application and simulation; big data set classification; classification algorithm; radial basis function neural network; RBNN","Text classification technology, an important basis for text mining and information retrieval, is mainly to determine the text category according to the text content under a predetermined set of categories. Traditional manual text categorization has gradually failed to meet the needs, while automatic text categorization based on artificial intelligence has become an important research direction in the field of natural language processing. To this end, this paper introduced the RBNN-based classification algorithm by considering the high dimensionality, non-linearity and complex correlation between feature items, and the theoretical and feasibility analysis were carried out so as to apply it to text feature dimension reduction. Also, the effects of the distribution density of the radial basis function in the radial basis neural network and the normalized form of the input data on the classification results were studied. Through the computer simulation experiment, the influence rule of distribution density of the radial basis function in the radial basis neural network and the normalized form of the input data on the training precision and test accuracy of the classification process were demonstrated in the form of curves, which provides guidance for the application of RBNN in pattern recognition. [ABSTRACT FROM AUTHOR] Copyright of Journal of Intelligent & Fuzzy Systems is the property of IOS Press and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=139366237&site=bsi-live"
"Recent Progress on the Convergence of the Internet of Things and Artificial Intelligence.","Shi, Feifei; Ning, Huansheng; Huangfu, Wei; Zhang, Fan; Wei, Dawei; Hong, Tao; Daneshmand, Mahmoud","IEEE Network",="08908044",,="Sep-Oct2020","34","5","8","8","146012293","10.1109/MNET.011.2000009","IEEE","Article","ARTIFICIAL intelligence; DECISION making; INFORMATION retrieval; INTERNET of things; SMART cities","Artificial intelligence; Convergence; Internet of Things; Neural networks; Routing; Sensors; Smart cities","The overwhelming increase of ubiquitous data, connections, and services brings serious challenges, in particular facing the demanding requirements of the Internet of Things (IoT). In order to seek better solutions and achieve more efficient information retrieval, artificial intelligence (AI) serves as a strong technical earthquake and contributes a lot to data analysis and decision making. It plays a compelling role in prompting digital and intelligent services. In this article, we focus on and emphasize the great significance pertaining to the convergence of IoT and AI. We first elaborate two typical forms of AI, namely knowledge-enabled AI and data-driven AI, with a comparison between respective advantages and disadvantages. Then we survey recent progress relating to the convergence of AI throughout the IoT architecture, from the sensing layer through the network layer to the application layer. In addition, a case study of a smart city is presented illustrating the convergence between IoT and AI. Furthermore, we point out open issues worth further research. The convergence of IoT and AI marries the merits of both and enables strong capability of resolving a broad range of problems. [ABSTRACT FROM AUTHOR] Copyright of IEEE Network is the property of IEEE and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=146012293&site=bsi-live"
"Reddit 소셜미디어를 활용한 ChatGPT 에 대한 사용자의 감정 및 요구 분석.","나혜인; 이병희","Journal of Internet Computing & Services",="15980170",,="Apr2024","25","2","79","14","177442693","10.7472/jksii.2024.25.2.79","Korean Society for Internet Information","Article",,"Needmining; Reddit; Sentiment Analysis; Topic Modeling; 감성분석; 니드마이닝; 레딧; 토픽모델링; ChatGPT; Needmining; Reddit; Sentiment Analysis; Topic Modeling","ChatGPT, as a representative chatbot leveraging generative artificial intelligence technology, is used valuable not only in scientific and technological domains but also across diverse sectors such as society, economy, industry, and culture. This study conducts an explorative analysis of user sentiments and needs for ChatGPT by examining global social media discourse on Reddit. We collected 10,796 comments on Reddit from December 2022 to August 2023 and then employed keyword analysis, sentiment analysis, and need-mining-based topic modeling to derive insights. The analysis reveals several key findings. The most frequently mentioned term in ChatGPT-related comments is ""time,"" indicative of users' emphasis on prompt responses, time efficiency, and enhanced productivity. Users express sentiments of trust and anticipation in ChatGPT, yet simultaneously articulate concerns and frustrations regarding its societal impact, including fears and anger. In addition, the topic modeling analysis identifies 14 topics, shedding light on potential user needs. Notably, users exhibit a keen interest in the educational applications of ChatGPT and its societal implications. Moreover, our investigation uncovers various user-driven topics related to ChatGPT, encompassing language models, jobs, information retrieval, healthcare applications, services, gaming, regulations, energy, and ethical concerns. In conclusion, this analysis provides insights into user perspectives, emphasizing the significance of understanding and addressing user needs. The identified application directions offer valuable guidance for enhancing existing products and services or planning the development of new service platforms. [ABSTRACT FROM AUTHOR] Copyright of Journal of Internet Computing & Services is the property of Korean Society for Internet Information and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=177442693&site=bsi-live"
"Reframing search and recommendation as opportunities for communication for people with intellectual disability.","Sitbon, Laurianne; Brereton, Margot; Bircanin, Filip","Human-Computer Interaction",="07370024",,="2024","39","3/4","206","19","174908760","10.1080/07370024.2023.2247394","Taylor & Francis Ltd","Article","ARTIFICIAL intelligence; PEOPLE with intellectual disabilities; DISRUPTIVE innovations; INCLUSION (Disability rights); ASSISTIVE technology; DIGITAL technology; INTELLECTUAL disabilities","Co-design; Image search; Intellectual disability; research through design; Visual communication; Web search","AI-driven commercial innovations and the digital disruptions they create, tend to accelerate faster than assistive technologies, and are rarely designed with inclusion and diversity in mind. We explore the joint value of research through design and co-design to give a voice to users with intellectual disability to set new directions for inclusive innovation. To do this, we present an account of, and a reflection on, the reframing that took place throughout a research program that has evolved over the last 8 years, presented through the lens of 3 case studies. These illustrate turning points in the frames of the research and its journey through the disciplinary traditions of Information Retrieval and Human Computer Interaction (HCI). The contributions of this paper are threefold. First, we contribute knowledge on the value of research through design to identify new frames for inclusive intelligent systems. Second, we extend inclusive co-design approaches to employing working prototypes that can support participant's voice about the design of the algorithms that underpin intelligent systems. We highlight how these working prototypes nurture the importance of participation and observation. Third, we contribute new frames for inclusive information retrieval, with new perspectives on intent, particularly in the context of image search. [ABSTRACT FROM AUTHOR] Copyright of Human-Computer Interaction is the property of Taylor & Francis Ltd and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=174908760&site=bsi-live"
"RegTech—the application of modern information technology in regulatory affairs: areas of interest in research and practice.","Becker, Michael; Merz, Kevin; Buchkremer, Rüdiger","Intelligent Systems in Accounting, Finance & Management",="1055615X",,="Oct2020","27","4","161","7","147826134","10.1002/isaf.1479","Wiley-Blackwell","Article","INFORMATION technology; ARTIFICIAL intelligence; INFORMATION retrieval; BLOCKCHAINS; SCIENTIFIC literature","artificial intelligence; compliance management; distributed ledger technologies; regulatory technology; risk management","Summary: We provide a high‐level view on topics addressed in scientific articles about regulatory technology (RegTech), with a particular focus on technologies used. For this purpose, we first explore different denominations for RegTech and derive search queries to search relevant literature portals. From the hits of that information retrieval process, we select 55 articles outlining the application of information technology in regulatory affairs with an emphasis on the financial sector. In comparison, we examine the technological scope of 347 RegTech companies and compare our findings with the scientific literature. Our research reveals that 'compliance management' is the most relevant topic in practice, and 'risk management' is the primary subject in research. The most significant technologies as of today are 'artificial intelligence' and distributed ledger technologies such as 'blockchain'. [ABSTRACT FROM AUTHOR] Copyright of Intelligent Systems in Accounting, Finance & Management is the property of Wiley-Blackwell and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=147826134&site=bsi-live"
"Similarity Search Algorithms in Knowledge Management Systems: A Review.","Naman, Sumiran; Vadari, Sekhar; Anantha Desik, P. H.","IUP Journal of Knowledge Management",="25834592",,="Apr2022","20","2","75","13","158128857",,"IUP Publications","Article","KNOWLEDGE management; SEARCH algorithms; INFORMATION storage & retrieval systems; NATURAL language processing; INFORMATION retrieval",,"The similarity search algorithm plays a major role in text-based Knowledge Management (KM) systems for information retrieval, search, and acquisition. The KM systems in business application domains are mainly required to use the existing history of the application knowledge for information retrieval and for the search to be faster and results to be accurate. Typically, KM systems generate information from internal sources, and therefore require greater accuracy and faster response times. There are already many models available in the Natural Language Processing (NLP) and Deep Learning (DL) arena which support similarity search. The DL models, though are very accurate, require a lot of memory and a lot of data, and are yet slower compared to the NLP methods. This paper primarily discusses a few text-based search and similarity methods, proposes three methods which are different in nature but faster and accurate when applied to KM system of business applications. A comparison of these techniques in terms of accuracy and speed on given datasets with examples is presented. [ABSTRACT FROM AUTHOR] Copyright of IUP Journal of Knowledge Management is the property of IUP Publications and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=158128857&site=bsi-live"
"Text Stemming and Lemmatization of Regional Languages in Indonesia: A Systematic Literature Review.","Abidin, Zaenal; Junaidi, Akmal; Wamiliana","Journal of Information Systems Engineering & Business Intelligence",="25986333",,="Jun2024","10","2","217","15","178791725","10.20473/jisebi.10.2.217-231","Universitas Airlangga","Article","NATURAL language processing; INFORMATION retrieval; INDONESIA; STEMMING (Linguistics); VOCABULARY; MORPHOLOGY (Grammar)","Lemmatization; Morphology; Rule-based; Stemming; Systematic Literature Review","Background: Stemming is significantly essential in natural language processing (NLP) due to the ability to minimize word variations to fundamental forms. This procedure facilitates the analysis of textual data and enhances the precision of classification and information retrieval. Objective: Previous related systematic literature review has not been conducted on stemming and lemmatization in regional languages in Indonesia. Therefore, this study aims to conduct a systematic literature review to capture the latest developments in stemming and lemmatization in regional languages in Indonesia. Methods: This study was carried out using Kitchenham method, analyzing 35 studies extracted from 740, which were obtained from Scopus, IEEE Xplore, and Google Scholar, and published between 2014 and 2023. Results: The results showed that study trends in stemming possessed the potential to continue developing every year. Additionally, the main element in stemming and lemmatization studies was found to be the availability of digital dictionaries in regional languages. This was because greater number of basic vocabularies contributed more positively to stemming or lemmatization. The availability of word morphology information in regional languages would be constructive for making rulebased stemmers. Meanwhile, corpus-based stemming and lemmatization studies could only be conducted for languages with a large corpus to ensure there were various affixed words to process. Conclusion: Based on SLR study, stemming and lemmatization in regional languages in Indonesia developed significantly from 2014 to 2023. The two main strategies applied included using available digital dictionaries and language morphology information. However, the main challenges encountered were the limited number of vocabulary words in the dictionaries and testing various rule-based methods. [ABSTRACT FROM AUTHOR] Copyright of Journal of Information Systems Engineering & Business Intelligence is the property of Universitas Airlangga and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=178791725&site=bsi-live"
"The false positives and false negatives of generative AI detection tools in education and academic research: The case of ChatGPT.","Dalalah, Doraid; Dalalah, Osama M.A.","International Journal of Management Education (Elsevier Science)",="14728117",,="Jul2023","21","2","N.PAG","1","164155973","10.1016/j.ijme.2023.100822","Elsevier B.V.","Article","ARTIFICIAL intelligence; CHATGPT","Artificial intelligence; ChatGPT; False positive/negative; Generative pre-trained transformer; Machine generated contents (MGC); Text generation","Generative Pre-trained Transformers like ChatGPT are examples of AI systems which produce human-like responses in different forms such as text or images that have demonstrated excellent performance in producing logical and contextually relevant answers. However, the false positive/negative detection of generative AI has been noted as a challenge. In this article, statistical experiments are conducted to test the chances of false positive and false negative detection of AI-generated text. It was found that the detected likelihoods of generative AI in articles' abstracts is much lower than that found in paragraphs taken from the literature section of the selected articles. This means that literature parts have higher likelihoods to falsely demonstrate AI-generated text. On the other hand, when genuine texts are compared with AI-generated texts, it is observed that there is a noticeable margin of overlap between their distributions and therefore type I and type II errors fall within the realm of possibility. We show that despite these challenges, generative AI like ChatGPT continues to be a promising tool for communication and information retrieval. However, it is vital to address the concerns regarding false detection of AI generated text and ensure that these models are used in ethical and responsible conduct. • The study focuses on false positive and false negative detection of ChatGPT-generated text. • False positives seem to be more serious, and the detection tools need to be enhanced. • Literature parts have a higher likelihood of falsely demonstrating AI-generated text. • ChatGPT remains a promising tool, but ethical and responsible conduct is essential for its use. [ABSTRACT FROM AUTHOR] Copyright of International Journal of Management Education (Elsevier Science) is the property of Elsevier B.V. and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=164155973&site=bsi-live"
"The future decisions of RoboJudge HHJ Arthur Ian Blockchain: Dread, delight or derision?,.","Castell, Stephen","Computer Law & Security Review",="2212473X",,="Aug2018","34","4","739","15","130965285","10.1016/j.clsr.2018.05.011","Elsevier B.V.","Article","BLOCKCHAINS; DISTRIBUTED computing; DATA protection laws; CRYPTOCURRENCIES; SECURITY systems; LAW; Security Systems Services (except Locksmiths); INFORMATION technology laws","Algorithm; Blockchain; Crypto; Ethic; Intelligence; Robot","Steve Saxby's prescient founding of CLSR , two hundred issues ago, encouraged and resonated with my own digital visionary thinking and professional activity in the evolving field of ICT and the Law. From Infolex , the UK's first commercially-available computer-assisted legal information retrieval service, and my APPEAL Report (on the admissibility of computer evidence in court and the legal reliability/security of IT systems), via my Forensic Systems Analysis expert methodology, to the nascent CryptoBlockTV , Steve's scholarly foresight in promoting adventurous exploration of ‘digilaw’ high-ground topics and issues has presented me with opportunities to generate a stream of prescient material, for which I am immensely grateful. And what is beyond prescient today is that the Coming of the Robots is unstoppable. The Artificial Intelligence (AI) Age is upon us; RoboJudge has all but already arrived. While many are concerned about defining and developing Machine Ethics, Castell's Second Dictum: “You cannot construct an algorithm that will reliably decide whether or not any algorithm is ethical” reveals that this is a futile exercise. Algorithms are also pivotal to the current mania for Crypto-Algorithmic Blockchain Technology Initial Coin Offerings (ICOs), with a ‘Crypto Tribe’ of Millennials relentlessly raising billions in real money thereby, to the extent that I have dubbed Crypto the Millennials’ Rock'n’Roll . The seasoned ICT expert professional however bears in mind that there are as yet no ISO standards for blockchain, and there is far more to creating and delivering a complete quality-assured system than just the blockchain component. Furthermore, the legal status of cryptocurrency, smart contract and distributed ledger technology is not clear or uncontentious – and there is already ICO litigation on foot. Nevertheless, taking my limerick-writing Castell GhostWriteBot ’s advice, it is perhaps time for my own asset-linked ICO, to launch my CapChere.com concept designed to reboot Capitalism and achieve ubiquitous universal share and wealth ownership . Look out for Castell GhostWriteBot ’s account (with or without limericks) of how I fared, in the 400th issue of CLSR . [ABSTRACT FROM AUTHOR] Copyright of Computer Law & Security Review is the property of Elsevier B.V. and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=130965285&site=bsi-live"
"Timely need for navigating the potential and downsides of LLMs in healthcare and biomedicine.","Ray, Partha Pratim","Briefings in Bioinformatics",="14675463",,="May2024","25","3","1","3","177375839","10.1093/bib/bbae214","Oxford University Press / USA","Article","MEDICAL personnel; MEDICAL care; TEXT summarization; LANGUAGE models; COACHING psychology; MEDICAL terminology; HEALTH information technology",,"The article titled ""Timely need for navigating the potential and downsides of LLMs in healthcare and biomedicine"" provides a comprehensive exploration of the opportunities and challenges associated with large language models (LLMs) in the field of biomedicine and healthcare. The authors discuss the transformative potential of LLMs in areas such as biomedical information retrieval, question answering, medical text summarization, information extraction, and medical education. They also highlight the need for caution regarding data privacy, ethical considerations, and the mitigation of biases. The article presents a list of popular LLMs in the health domain and identifies limitations and new challenges, along with mitigation strategies. Additionally, it suggests various applications of LLMs in healthcare, including personalized treatment recommendations, predictive health analytics, and automated medical literature review. The authors emphasize the importance of proceeding with ethical principles, inclusivity, and collaboration in integrating LLMs into healthcare. While the article provides valuable insights, it could have further explored futuristic challenges and applications of LLMs in the biomedical domain. Overall, this work contributes to the ongoing discourse on the role of AI in healthcare and sets the stage for future research and development in this field. [Extracted from the article] Copyright of Briefings in Bioinformatics is the property of Oxford University Press / USA and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=177375839&site=bsi-live"
"Tweet Segmentation and Its Application to Named Entity Recognition.","Li, Chenliang; Sun, Aixin; Weng, Jianshu; He, Qi","IEEE Transactions on Knowledge & Data Engineering",="10414347",,="Feb2015","27","2","558","13","100151028","10.1109/TKDE.2014.2327042","IEEE","Article","INFORMATION retrieval; NATURAL language processing; ENTITY-relationship modeling; MICROBLOGS; LINGUISTIC analysis","Context; Electronic publishing; Encyclopedias; Internet; Pragmatics; Semantics","Twitter has attracted millions of users to share and disseminate most up-to-date information, resulting in large volumes of data produced everyday. However, many applications in Information Retrieval (IR) and Natural Language Processing (NLP) suffer severely from the noisy and short nature of tweets. In this paper, we propose a novel framework for tweet segmentation in a batch mode, called HybridSeg. By splitting tweets into meaningful segments, the semantic or context information is well preserved and easily extracted by the downstream applications. HybridSeg finds the optimal segmentation of a tweet by maximizing the sum of the stickiness scores of its candidate segments. The stickiness score considers the probability of a segment being a phrase in English (i.e., global context) and the probability of a segment being a phrase within the batch of tweets (i.e., local context). For the latter, we propose and evaluate two models to derive local context by considering the linguistic features and term-dependency in a batch of tweets, respectively. HybridSeg is also designed to iteratively learn from confident segments as pseudo feedback. Experiments on two tweet data sets show that tweet segmentation quality is significantly improved by learning both global and local contexts compared with using global context alone. Through analysis and comparison, we show that local linguistic features are more reliable for learning local context compared with term-dependency. As an application, we show that high accuracy is achieved in named entity recognition by applying segment-based part-of-speech (POS) tagging. [ABSTRACT FROM PUBLISHER] Copyright of IEEE Transactions on Knowledge & Data Engineering is the property of IEEE and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=100151028&site=bsi-live"
"WabiQA: A Wikipedia-Based Thai Question-Answering System.","Noraset, Thanapon; Lowphansirikul, Lalita; Tuarob, Suppawong","Information Processing & Management",="03064573",,="Jan2021","58","1","N.PAG","1","147405621","10.1016/j.ipm.2020.102431","Elsevier B.V.","Article","NATURAL language processing; INFORMATION retrieval; SEARCH engines; THAILAND; THAI language; DEEP learning; QUESTION answering systems; MOBILE apps; GOOGLE (Web resource); WIKIPEDIA","Creative Language Processing; Deep Learning; Question Answering System","• We propose WabiQA, a novel Thai QA system that implements a BM25F-based document retriever and a bi-directional LSTM document reader. • We compare different document retrieval methods, including Google Search API, TF-IDF, and BM25F, and also study the impacts of different features in the bi-directional LSTM reader. • WabiQA outperforms other Thai QA systems by 31.48% in terms of document retrieval accuracy, and 198.83% in terms of answer prediction F1. • WabiQA is developed as part of a prototype mobile application aiming to facilitate users with visual impairment. With vast information that has been digitized and made available online, manually finding the answer to a question can be tedious. While search engines have emerged to facilitate information needs, users would have to manually read through the retrieved articles to locate the answer to a specific question. Therefore, the ability to automatically understand users' natural language questions and find the correct answers could prove crucial in information retrieval. Indeed, such automatic question-answering solutions have been extensively studied by the natural language processing (NLP) research communities. However, most of the development targets questions and information sources composed in high-resource languages such as English and Chinese. In this paper, we propose WabiQA , a novel system for automatically answering questions in the Thai language using the Thai Wikipedia articles as the knowledge source. Specifically, the proposed method first retrieves the Wikipedia article that is most likely to contain the answer. Then, a bi-directional LSTM model is used to read the article and locate candidate answers, which are ranked by confidence levels and returned to the user. WabiQA won the first prize award from Thailand's National Software Contest 2019 under category ""Question-Answering Program from Thai Wikipedia,"" with 83.5%, 34.80%, and 45.96%, and outperforming the next best competitors' systems by 19.99, 24.26, and 33.10 percentage points in terms of Accuracy@1, EM, and F1 respectively. Furthermore, we also develop a prototype mobile application that aims to facilitate Thai users with visual impairment using voice-to-speech technology and an intelligent question-answer categorization. The findings of this research not only expand the horizon of the possibility to develop intelligent NLP applications for the Thai language using only available existing Thai NLP tools, resources, and deep learning technologies, but also shed light on the possibility to apply such techniques to develop many intelligent NLP tasks for the Thai and other low-resource languages such as reading assessment, writing assistance, and entity linking. [ABSTRACT FROM AUTHOR] Copyright of Information Processing & Management is the property of Pergamon Press - An Imprint of Elsevier Science and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=147405621&site=bsi-live"
"WETA: Automatic taxonomy alignment via word embeddings.","Giabelli, Anna; Malandri, Lorenzo; Mercorio, Fabio; Mezzanzanica, Mario","Computers in Industry",="01663615",,="Jun2022","138",,"N.PAG","1","156127908","10.1016/j.compind.2022.103626","Elsevier B.V.","Article","INFORMATION retrieval; INFORMATION sharing; TAXONOMY","Human-AI; Real-life Application; Taxonomy Alignment; Word Embedding","Lexical taxonomies are widely used to foster information retrieval and exchange in several domains and applications. When there are multiple taxonomies, heterogeneity among them is a severe problem for efficient collaboration processes. In this paper, we propose WETA, a domain-independent, knowledge-poor method for automatic taxonomy alignment via word embeddings. WETA associates all the leaf terms of the origin taxonomy to one or many concepts in the destination taxonomy, employing a scoring function, which merges the score of a hierarchical method based on cosine similarity and the score of a classification task. WETA is developed in the context of an EU Grant aiming at bridging the national taxonomies of EU countries towards the European Skills, Competences, Qualifications and Occupations taxonomy (ESCO) using AI Algorithms. The results, validated within the EU project activities for bridging the Italian occupation taxonomy CP and ESCO, confirm the usefulness of WETA in supporting the automatic alignment of national labor taxonomies. WETA reaches a 0.8 accuracy on recommending top-5 occupations and a wMRR of 0.72. WETA reduces the human effort needed for building a mapping from scratch: it would allow domain experts to concentrate on the validation task and decrease the incoherence due to multiple judgments. It would also make the approach reproducible and transparent to policymakers. • A taxonomy alignment method, that exploits word embeddings and blends two different approaches to help the domain experts. • The first method suggests n concepts of the destination taxonomy, leveraging their similarity in a word embedding model. • The second method is based on a classification task, and it suggests n concepts as the hierarchical one. • We develop the approach within a European project to bridge national to the ESCO occupation taxonomy. [ABSTRACT FROM AUTHOR] Copyright of Computers in Industry is the property of Elsevier B.V. and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=156127908&site=bsi-live"
"ФОРМУВАННЯ ІНТЕЛЕКТУАЛЬНИХ СИСТЕМ ІНВЕСТИЦІЙНОЇ ПРИВАБЛИВОСТІ БУДІВЕЛЬНИХ ПІДПРИЄМСТВ ТА ВИЗНАЧЕННЯ ВПЛИВУ НА НИХ СТЕЙКХОЛДЕРІВ.","К., Мамонов; В., Єсіна; Н., Матвєєва; О., Славута; В., Троян","Financial & Credit Activity: Problems of Theory & Practice",="23064994",,="2022","2","43","193","9","159728097","10.55643/fcaptp.2.43.2022.3363","University of Banking of the National Bank of Ukraine","Article","ARTIFICIAL intelligence; CONSTRUCTION industry; PROBLEM solving; INFORMATION retrieval; SYSTEMS software; Residential building construction","construction companies; investment attractiveness; partners; stakeholders; system; будівельні підприємства; партнери; система; стейкхолдери; інвестиційна привабливість","The necessity of rethinking the approaches to ensuring the management of enterprises on the basis of forming a quantitative basis for making sound management decisions is determined. In addition, there are ambiguous processes in the economic country that are characterized by a lack of system and clear anti-epidemic actions and lead to an increase in the number of patients. It is established that, in such conditions, the use of modern intelligent systems to ensure the investment attractiveness of enterprises as important elements for their growth and development of the country's economy is of particular importance. Generalizing the existing theoretical and methodological provisions, it is proposed to define intelligent systems as a modern complex toolkit based on the use of artificial intelligence, using technological means of developing expert, recommendatory, intelligent information retrieval, calculation, and logic systems based on information base, that is aimed at solving problems., defining algorithms, and software systems, that can replace a person and create a basis for decision making. To assess the investment attractiveness as an important factor in the development of construction companies, it is proposed to apply an integrated approach based on a multilevel system of indicators determined by local and generalizing factors. Stakeholders of construction enterprises and their types are defined, and local and integral models for estimation of the level of interaction of stakeholders are offered. Based on the application of methods of economic and mathematical modeling, the level of influence of the level of stakeholder interaction on the investment attractiveness of construction companies is determined. This allowed forming a quantitative basis for the development of intelligent systems in the context of making sound management decisions. [ABSTRACT FROM AUTHOR] Copyright of Financial & Credit Activity: Problems of Theory & Practice is the property of University of Banking of the National Bank of Ukraine and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=159728097&site=bsi-live"
"생성형 AI의 신뢰도에 대한 탐색적 연구.","김 소 연; 조 지 연; 이 봉 규","Journal of Internet Computing & Services",="15980170",,="Feb2024","25","1","79","12","177478570","10.7472/jksii.2024.25.1.79","Korean Society for Internet Information","Article",,"ChatGPT; Continued Use Intention; Expectation-Confirmation Model; Generative AI; Trust; 기대충족모델; 생성형 AI; 신뢰; 지속사용의도; ChatGPT; Continued Use Intention; Expectation-Confirmation Model; Generative AI; Trust","This study focused on user trust in ChatGPT, a generative AI technology, and explored the factors that affect usage status and intention to continue using, and whether the influence of trust varies depending on the purpose. For this purpose, the survey was conducted targeting people in their 20s and 30s who use ChatGPT the most. The statistical analysis deploying IBM SPSS 27 and SmartPLS 4.0. A structural equation model was formulated on the foundation of Bhattacherjee’s Expectation-Confirmation Model (ECM), employing path analysis and Multi-Group Analysis (MGA) for hypothesis validation. The main findings are as follows: Firstly, ChatGPT is mainly used for specific needs or objectives rather than as a daily tool. The majority of users are cognizant of its hallucination effects; however, this did not hinder its use. Secondly, the hypothesis testing indicated that independent variables such as expectation confirmation, perceived usefulness, and user satisfaction all exert a positive influence on the dependent variable, the intention for continuance intention. Thirdly, the influence of trust varied depending on the user’s purpose in utilizing ChatGPT. trust was significant when ChatGPT is used for information retrieval but not for creative purposes. This study will be used to solve reliability problems in the process of introducing generative AI in society and companies in the future and to establish policies and derive improvement measures for successful employment. [ABSTRACT FROM AUTHOR] Copyright of Journal of Internet Computing & Services is the property of Korean Society for Internet Information and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)","https://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=177478570&site=bsi-live"
