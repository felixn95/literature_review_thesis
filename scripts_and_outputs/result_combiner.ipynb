{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T21:24:10.969474Z",
     "start_time": "2024-11-29T21:24:10.965337Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "25383379964c88a6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-29T21:24:11.034553Z",
     "start_time": "2024-11-29T21:24:11.009603Z"
    }
   },
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bibtexparser\n",
    "\n",
    "# Constants\n",
    "STANDARD_COLUMNS = ['Database', 'DOI', 'Title', 'Author', 'Year', 'Abstract', 'REVIEW_STAGE']\n",
    "NOT_FOUND_VALUE = 'NOT_FOUND'\n",
    "DEFAULT_REVIEW_STAGE = 'unchecked'\n",
    "\n",
    "COLUMN_MAPPINGS = {\n",
    "    'DOI': ['doi', 'DOI', 'digitalObjectIdentifier'],\n",
    "    'Title': ['title', 'Article Title', 'Document Title', 'Article title', 'Title'],\n",
    "    'Author': ['author', 'Authors', 'Author'],\n",
    "    'Year': ['year', 'Publication Year', 'Publication Date'],\n",
    "    'Abstract': ['Abstract', 'abstract']\n",
    "}\n",
    "\n",
    "# File names to process\n",
    "file_list = [\n",
    "    'results_review_incl_RAG/ieeexplore_85.bib',\n",
    "    'results_review_incl_RAG/ProQuestDocuments_1-100.xls',\n",
    "    'results_review_incl_RAG/ProQuestDocuments_101-150.xls',\n",
    "    'results_review_incl_RAG/ScienceDirect_citations_1-100.bib',\n",
    "    'results_review_incl_RAG/ScienceDirect_citations_101-184.bib',\n",
    "    'results_review_incl_RAG/ebsohost_1-50.csv',\n",
    "    'results_review_incl_RAG/ebsohost_1-94.csv',\n",
    "    'results_review_incl_RAG/TaylorFrancis_36.bib',\n",
    "    'results_review_incl_RAG/acm_126.bib',\n",
    "    'results_review_incl_RAG/webofscience_150.xls'\n",
    "]\n",
    "\n",
    "# Mapping from filename patterns to database names\n",
    "DATABASE_MAPPING = {\n",
    "    'ProQuestDocuments': 'ProQuest',\n",
    "    'ScienceDirect_citations': 'ScienceDirect',\n",
    "    'TaylorFrancis': 'Taylor & Francis',\n",
    "    'acm': 'ACM Digital Library',\n",
    "    'ebsohost': 'EBSCOhost',\n",
    "    'ieeexplore': 'IEEE Xplore',\n",
    "    'webofscience': 'Web of Science',  # Adjusted for potential typo\n",
    "}\n",
    "\n",
    "def get_database_name(filename):\n",
    "    for key in DATABASE_MAPPING.keys():\n",
    "        if filename.startswith(key):\n",
    "            return DATABASE_MAPPING[key]\n",
    "    return 'Unknown'\n",
    "\n",
    "def process_file(filepath):\n",
    "    filename = os.path.basename(filepath)\n",
    "    file_extension = os.path.splitext(filename)[1].lower()\n",
    "    database = get_database_name(filename)\n",
    "    \n",
    "    if file_extension in ['.xls', '.xlsx']:\n",
    "        df = pd.read_excel(filepath)\n",
    "    elif file_extension == '.csv':\n",
    "        df = pd.read_csv(filepath, encoding='utf-8')\n",
    "    elif file_extension == '.bib':\n",
    "        df = process_bibtex_file(filepath)\n",
    "    else:\n",
    "        print(f\"Unsupported file type: {filepath}\")\n",
    "        return None\n",
    "    \n",
    "    # Map columns to standard names\n",
    "    df = map_columns(df)\n",
    "    \n",
    "    # Add 'Database' column\n",
    "    df['Database'] = database\n",
    "    \n",
    "    # Add 'REVIEW_STAGE' column with default value\n",
    "    df['REVIEW_STAGE'] = DEFAULT_REVIEW_STAGE\n",
    "    \n",
    "    # Ensure all standard columns are present and handle missing data\n",
    "    for col in STANDARD_COLUMNS:\n",
    "        if col not in df.columns:\n",
    "            df[col] = NOT_FOUND_VALUE\n",
    "    \n",
    "    # Replace NaN or empty strings with NOT_FOUND_VALUE\n",
    "    df[STANDARD_COLUMNS] = df[STANDARD_COLUMNS].replace(\n",
    "        {pd.NA: NOT_FOUND_VALUE, np.nan: NOT_FOUND_VALUE, '': NOT_FOUND_VALUE}\n",
    "    )\n",
    "    \n",
    "    # Keep only the standard columns\n",
    "    df = df[STANDARD_COLUMNS]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_bibtex_file(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as bibtex_file:\n",
    "        bib_database = bibtexparser.load(bibtex_file)\n",
    "    entries = bib_database.entries\n",
    "    df = pd.DataFrame(entries)\n",
    "    return df\n",
    "\n",
    "def map_columns(df):\n",
    "    # Create a mapping from lowercase column names to actual column names\n",
    "    lower_columns = {col.lower(): col for col in df.columns}\n",
    "    column_mapping = {}\n",
    "    for standard_col, possible_names in COLUMN_MAPPINGS.items():\n",
    "        for possible_name in possible_names:\n",
    "            possible_name_lower = possible_name.lower()\n",
    "            if possible_name_lower in lower_columns:\n",
    "                actual_col_name = lower_columns[possible_name_lower]\n",
    "                column_mapping[actual_col_name] = standard_col\n",
    "                break\n",
    "    df = df.rename(columns=column_mapping)\n",
    "    return df\n",
    "\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\FelixNeubauer\\UniRepos\\literature_review_thesis\\scripts_and_outputs_incl_rag\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T21:24:13.588203Z",
     "start_time": "2024-11-29T21:24:11.045526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Processing files in a Jupyter notebook\n",
    "all_dfs = []\n",
    "\n",
    "for file in file_list:\n",
    "    print(f\"Processing {file}\")\n",
    "    df = process_file(file)\n",
    "    if df is not None:\n",
    "        all_dfs.append(df)\n",
    "\n",
    "if all_dfs:\n",
    "    combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    # Save combined dataframe to Excel\n",
    "    combined_df.to_excel('combined_results.xlsx', index=False)\n",
    "    print(\"Combined dataframe saved to 'combined_results.xlsx'\")\n",
    "else:\n",
    "    print(\"No dataframes to combine.\")"
   ],
   "id": "4ba68a72f4f60eff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing results_review_incl_RAG/ieeexplore_85.bib\n",
      "Processing results_review_incl_RAG/ProQuestDocuments_1-100.xls\n",
      "Processing results_review_incl_RAG/ProQuestDocuments_101-150.xls\n",
      "Processing results_review_incl_RAG/ScienceDirect_citations_1-100.bib\n",
      "Processing results_review_incl_RAG/ScienceDirect_citations_101-184.bib\n",
      "Processing results_review_incl_RAG/ebsohost_1-50.csv\n",
      "Processing results_review_incl_RAG/ebsohost_1-94.csv\n",
      "Processing results_review_incl_RAG/TaylorFrancis_36.bib\n",
      "Processing results_review_incl_RAG/acm_126.bib\n",
      "Processing results_review_incl_RAG/webofscience_150.xls\n",
      "Combined dataframe saved to 'combined_results.xlsx'\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T21:24:13.593583Z",
     "start_time": "2024-11-29T21:24:13.590215Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "23b9053d0416afc0",
   "outputs": [],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
