{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-28T12:22:15.089114Z",
     "start_time": "2024-11-28T12:22:13.343373Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# Constants\n",
    "INPUT_FILE = 'dublette_cleaned_results_final.xlsx'\n",
    "OUTPUT_FILE = 'processed_results.xlsx'\n",
    "OPENAI_MODEL = 'gpt-4o'\n",
    "MAX_ROWS = 10  # Number of entries to process\n",
    "load_dotenv()\n",
    "# Instantiate the OpenAI client\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_APIKEY'))  # You can omit the api_key if it's set in your environment\n",
    "\n",
    "# Prompt Template\n",
    "PROMPT_TEMPLATE = '''\n",
    "You are helping to categorize the potential value of a paper by its title + abstract. These are the research questions that potentially shall be answered in the literature review:\n",
    "Q1: What requirements should AI-based solutions for efficient knowledge management/retrieval in (the corporate context) fulfill? (can be from the users or any stakeholders perspective, but also generally or technically, at best it should be conversational solutions or retrieval from internal knowledge)\n",
    "Q2: Which design principles can be derived from such requirements to achieve such implementations successfully?\n",
    "\n",
    "Title: {Title}\n",
    "Abstract: {Abstract}\n",
    "\n",
    "Now be critical and try to categorize the paper in one of the following stages:\n",
    "NOT_RELEVANT -> Paper probably can't answer any of the topics. Or it's a too specific use case that can't be transferred.\n",
    "MAYBE_RELEVANT -> Paper might answer any of the topics. It's worth taking a closer look.\n",
    "RELEVANT -> Paper seems to have potential to address any topics of the research.\n",
    "NOT_FOUND -> No abstract was found / no successful request or response\n",
    "\n",
    "Please try to think as a researcher; it is okay to be critical and to discard papers as not relevant.\n",
    "\n",
    "Your answer should be in plain json format to directly process it, like:\n",
    "{{\n",
    "\"CATEGORY\": \"RELEVANT\",\n",
    "\"REASON\": \"your reason in one or two sentences\"\n",
    "}}\n",
    "'''\n",
    "\n",
    "# Function to process each paper\n",
    "def categorize_paper(title: str, abstract: str):\n",
    "    if pd.isna(abstract) or abstract.strip() == '' or abstract.strip().upper() == 'NOT_FOUND':\n",
    "        return 'NOT_FOUND', 'No abstract was found / no successful request or response.'\n",
    "\n",
    "    prompt = PROMPT_TEMPLATE.format(Title=title, Abstract=abstract)\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=OPENAI_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=150,\n",
    "            n=1,\n",
    "            temperature=0.0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        reply = response.choices[0].message.content\n",
    "        result = json.loads(reply)\n",
    "        category = result.get('CATEGORY', 'NOT_FOUND')\n",
    "        reason = result.get('REASON', '')\n",
    "    except json.JSONDecodeError:\n",
    "        category = 'NOT_FOUND'\n",
    "        reason = 'Could not parse the response as JSON.'\n",
    "    except Exception as e:\n",
    "        category = 'NOT_FOUND'\n",
    "        reason = f'Error during API call: {str(e)}'\n",
    "        print (reason)\n",
    "\n",
    "    return category, reason\n",
    "\n",
    "# Main processing function\n",
    "def process_papers():\n",
    "    # Load the data\n",
    "    df = pd.read_excel(INPUT_FILE)\n",
    "\n",
    "    # Insert new columns at the beginning\n",
    "    df.insert(0, 'GPT_STAGING', '')\n",
    "    df.insert(1, 'REASON', '')\n",
    "\n",
    "    # Process each paper\n",
    "    for idx, row in df.head(MAX_ROWS).iterrows():\n",
    "        title = row['Title']\n",
    "        abstract = row['Abstract']\n",
    "        category, reason = categorize_paper(title, abstract)\n",
    "        df.at[idx, 'GPT_STAGING'] = category\n",
    "        df.at[idx, 'REASON'] = reason\n",
    "        print(f'Processed paper {idx+1}/{MAX_ROWS}: {category}')\n",
    "\n",
    "    # Save the results\n",
    "    df.to_excel(OUTPUT_FILE, index=False)\n",
    "    print(f'\\nProcessing complete. Results saved to {OUTPUT_FILE}')\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T12:22:30.958501Z",
     "start_time": "2024-11-28T12:22:15.090640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Process the papers\n",
    "process_papers()"
   ],
   "id": "6a2ab4d545b1d293",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed paper 1/10: NOT_RELEVANT\n",
      "Processed paper 2/10: MAYBE_RELEVANT\n",
      "Processed paper 3/10: MAYBE_RELEVANT\n",
      "Processed paper 4/10: NOT_RELEVANT\n",
      "Processed paper 5/10: NOT_RELEVANT\n",
      "Processed paper 6/10: NOT_RELEVANT\n",
      "Processed paper 7/10: MAYBE_RELEVANT\n",
      "Processed paper 8/10: MAYBE_RELEVANT\n",
      "Processed paper 9/10: NOT_RELEVANT\n",
      "Processed paper 10/10: MAYBE_RELEVANT\n",
      "\n",
      "Processing complete. Results saved to processed_results.xlsx\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T12:22:30.962529Z",
     "start_time": "2024-11-28T12:22:30.959508Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5d98cb29b3918c0e",
   "outputs": [],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
